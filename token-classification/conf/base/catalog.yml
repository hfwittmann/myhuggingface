# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

# dataset:
#   type: token_classification.extras.dataset.huggingface.HuggingfaceDataSet
#   subtype: null
#   filepath: data/01_raw/dataset/{split}
#   splits: [train, test, validation]
#   layer: 01_raw

# dataset_csv:
#   type: token_classification.extras.dataset.huggingface.HuggingfaceDataSet
#   subtype: csv
#   filepath: data/01_raw/dataset_{split}.csv
#   splits: [train, test, validation]
#   layer: 01_raw

dataset_json:
  type: token_classification.extras.dataset.huggingface.HuggingfaceDataSet
  subtype: json
  filepath: data/01_raw/dataset_{split}.json
  splits: [train, test, validation]
  layer: 01_raw

dataset_tokenized_json:
  type: token_classification.extras.dataset.huggingface.HuggingfaceDataSet
  subtype: json
  filepath: data/02_intermediate/dataset_tokenized_{split}.json
  splits: [train, test, validation]
  layer: 02_intermediate

model:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/model.pkl
# evaluation:
#   type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
#   data_set:
#     type: json.JSONDataSet
#     filepath: data/08_reporting/evaluation.json
