{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Runproject.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPF7upv0LKn7+w5HqGUTgb6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"my3tE-7u69SC","executionInfo":{"status":"ok","timestamp":1657123894740,"user_tz":-120,"elapsed":21433,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"d415989b-ea9d-4207-b155-8fd734d4cd5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","source":["cd \"/content/gdrive/MyDrive/Colab Notebooks/myhuggingface/sequenceclassification\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TkWUOLf17rx_","executionInfo":{"status":"ok","timestamp":1657123894740,"user_tz":-120,"elapsed":12,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"79e5c8f3-98a6-454c-b69b-f824bfc9e3c4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/myhuggingface/sequenceclassification\n"]}]},{"cell_type":"code","source":["pip install transformers kedro datasets python-box h11"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2BS_wNB-4vA","executionInfo":{"status":"ok","timestamp":1657123919070,"user_tz":-120,"elapsed":24337,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"ce259f76-f37f-44fd-9e31-efebb0398b48"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 7.6 MB/s \n","\u001b[?25hCollecting kedro\n","  Downloading kedro-0.18.1-py3-none-any.whl (249 kB)\n","\u001b[K     |████████████████████████████████| 249 kB 69.8 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n","\u001b[K     |████████████████████████████████| 362 kB 73.2 MB/s \n","\u001b[?25hCollecting python-box\n","  Downloading python_box-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 57.0 MB/s \n","\u001b[?25hCollecting h11\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 49.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 10.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: setuptools>=38.0 in /usr/local/lib/python3.7/dist-packages (from kedro) (57.4.0)\n","Collecting toposort~=1.5\n","  Downloading toposort-1.7-py2.py3-none-any.whl (9.0 kB)\n","Collecting toml~=0.10\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 66.2 MB/s \n","\u001b[?25hCollecting pip-tools~=6.5\n","  Downloading pip_tools-6.8.0-py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 417 kB/s \n","\u001b[?25hCollecting python-json-logger~=2.0\n","  Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB)\n","Requirement already satisfied: click<9.0 in /usr/local/lib/python3.7/dist-packages (from kedro) (7.1.2)\n","Requirement already satisfied: cachetools~=4.1 in /usr/local/lib/python3.7/dist-packages (from kedro) (4.2.4)\n","Collecting anyconfig~=0.10.0\n","  Downloading anyconfig-0.10.1-py2.py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.9 MB/s \n","\u001b[?25hCollecting dynaconf<4.0.0,>=3.1.2\n","  Downloading dynaconf-3.1.9-py2.py3-none-any.whl (202 kB)\n","\u001b[K     |████████████████████████████████| 202 kB 75.6 MB/s \n","\u001b[?25hCollecting fsspec<=2022.1,>=2021.4\n","  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 75.4 MB/s \n","\u001b[?25hCollecting gitpython~=3.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 79.3 MB/s \n","\u001b[?25hCollecting cookiecutter~=1.7.0\n","  Downloading cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n","Collecting pluggy~=1.0.0\n","  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n","Collecting rope~=0.21.0\n","  Downloading rope-0.21.1-py3-none-any.whl (185 kB)\n","\u001b[K     |████████████████████████████████| 185 kB 70.8 MB/s \n","\u001b[?25hCollecting jmespath<1.0,>=0.9.5\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting binaryornot>=0.4.4\n","  Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n","Collecting jinja2-time>=0.2.0\n","  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n","Collecting poyo>=0.5.0\n","  Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter~=1.7.0->kedro) (6.1.2)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from cookiecutter~=1.7.0->kedro) (1.15.0)\n","Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from cookiecutter~=1.7.0->kedro) (2.11.3)\n","Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from binaryornot>=0.4.4->cookiecutter~=1.7.0->kedro) (3.0.4)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<4.0.0,>=2.7->cookiecutter~=1.7.0->kedro) (2.0.1)\n","Collecting arrow\n","  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from pip-tools~=6.5->kedro) (0.37.1)\n","Collecting build\n","  Downloading build-0.8.0-py3-none-any.whl (17 kB)\n","Collecting pip>=21.2\n","  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 55.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify>=4.0.0->cookiecutter~=1.7.0->kedro) (1.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 76.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 81.6 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 76.3 MB/s \n","\u001b[?25h  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 74.8 MB/s \n","\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 68.5 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 73.4 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.6 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from arrow->jinja2-time>=0.2.0->cookiecutter~=1.7.0->kedro) (2.8.2)\n","Requirement already satisfied: pep517>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from build->pip-tools~=6.5->kedro) (0.12.0)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from build->pip-tools~=6.5->kedro) (2.0.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, smmap, asynctest, async-timeout, arrow, aiosignal, pyyaml, poyo, pip, jinja2-time, gitdb, fsspec, build, binaryornot, aiohttp, xxhash, toposort, toml, tokenizers, rope, responses, python-json-logger, pluggy, pip-tools, jmespath, huggingface-hub, gitpython, dynaconf, cookiecutter, anyconfig, transformers, python-box, kedro, h11, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","  Attempting uninstall: pluggy\n","    Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Attempting uninstall: pip-tools\n","    Found existing installation: pip-tools 6.2.0\n","    Uninstalling pip-tools-6.2.0:\n","      Successfully uninstalled pip-tools-6.2.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pytest 3.6.4 requires pluggy<0.8,>=0.5, but you have pluggy 1.0.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 anyconfig-0.10.1 arrow-1.2.2 async-timeout-4.0.2 asynctest-0.13.0 binaryornot-0.4.4 build-0.8.0 cookiecutter-1.7.3 datasets-2.3.2 dynaconf-3.1.9 frozenlist-1.3.0 fsspec-2022.1.0 gitdb-4.0.9 gitpython-3.1.27 h11-0.13.0 huggingface-hub-0.8.1 jinja2-time-0.2.0 jmespath-0.10.0 kedro-0.18.1 multidict-6.0.2 pip-22.1.2 pip-tools-6.8.0 pluggy-1.0.0 poyo-0.5.0 python-box-6.0.2 python-json-logger-2.0.2 pyyaml-5.4.1 responses-0.18.0 rope-0.21.1 smmap-5.0.0 tokenizers-0.12.1 toml-0.10.2 toposort-1.7 transformers-4.20.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"my0ZtFQ79-bj","executionInfo":{"status":"ok","timestamp":1657123924999,"user_tz":-120,"elapsed":315,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"a009a5cc-ab40-4544-9247-759d919de92a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.13\n"]}]},{"cell_type":"code","source":["# !kedro run\n","!kedro run"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILkif36DPbMQ","executionInfo":{"status":"ok","timestamp":1657124809145,"user_tz":-120,"elapsed":764443,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"7e6ac851-5ca8-49fb-ffc1-a6952916a28b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-07-06 16:14:05,144 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n","2022-07-06 16:14:05,165 - kedro.framework.session.session - WARNING - Unable to git describe /content/gdrive/MyDrive/Colab Notebooks/myhuggingface/sequenceclassification\n","2022-07-06 16:14:05,181 - kedro.framework.session.session - INFO - ** Kedro project sequenceclassification\n","2022-07-06 16:14:05,370 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n","/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n","  from numpy.dual import register_func\n","/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n","  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n","/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n","  import imp\n","/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2022-07-06 16:14:13,439 - kedro.pipeline.node - INFO - Running node: get_data_from_web: get_data_from_web(None) -> [dataset]\n","Downloading builder script: 4.41kB [00:00, 3.52MB/s]       \n","Downloading metadata: 2.04kB [00:00, 3.32MB/s]     \n","/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  from .mio5_utils import VarReader5\n","Downloading and preparing dataset yelp_review_full/yelp_review_full (download: 187.06 MiB, generated: 496.94 MiB, post-processed: Unknown size, total: 684.00 MiB) to /root/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf...\n","Downloading data: 100% 196M/196M [00:05<00:00, 37.5MB/s]\n","Dataset yelp_review_full downloaded and prepared to /root/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf. Subsequent calls will reuse this data.\n","100% 2/2 [00:00<00:00, 318.51it/s]\n","2022-07-06 16:14:53,360 - kedro.io.data_catalog - INFO - Saving data to `dataset` (PickleDataSet)...\n","2022-07-06 16:14:54,042 - kedro.runner.sequential_runner - INFO - Completed 1 out of 4 tasks\n","2022-07-06 16:14:54,042 - kedro.io.data_catalog - INFO - Loading data from `dataset` (PickleDataSet)...\n","2022-07-06 16:14:54,045 - kedro.pipeline.node - INFO - Running node: mytokenizer: mytokenizer([dataset]) -> [dataset_tokenized]\n","2022-07-06 16:14:54,055 - datasets.fingerprint - WARNING - Parameter 'function'=<function __tokenize_function at 0x7fde9c65dc20> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","100% 650/650 [04:54<00:00,  2.21ba/s]\n","100% 50/50 [00:22<00:00,  2.21ba/s]\n","2022-07-06 16:20:11,157 - kedro.io.data_catalog - INFO - Saving data to `dataset_tokenized` (PickleDataSet)...\n","2022-07-06 16:20:11,497 - kedro.runner.sequential_runner - INFO - Completed 2 out of 4 tasks\n","2022-07-06 16:20:11,497 - kedro.io.data_catalog - INFO - Loading data from `dataset_tokenized` (PickleDataSet)...\n","2022-07-06 16:20:11,641 - kedro.pipeline.node - INFO - Running node: train_n_eval_datasets: train_n_eval_datasets([dataset_tokenized]) -> [small_train_dataset,small_eval_dataset]\n","2022-07-06 16:20:11,779 - kedro.io.data_catalog - INFO - Saving data to `small_train_dataset` (PickleDataSet)...\n","2022-07-06 16:20:11,784 - kedro.io.data_catalog - INFO - Saving data to `small_eval_dataset` (PickleDataSet)...\n","2022-07-06 16:20:12,478 - kedro.runner.sequential_runner - INFO - Completed 3 out of 4 tasks\n","2022-07-06 16:20:12,478 - kedro.io.data_catalog - INFO - Loading data from `small_train_dataset` (PickleDataSet)...\n","2022-07-06 16:20:12,493 - kedro.io.data_catalog - INFO - Loading data from `small_eval_dataset` (PickleDataSet)...\n","2022-07-06 16:20:12,496 - kedro.pipeline.node - INFO - Running node: model_training: model_training([small_train_dataset,small_eval_dataset]) -> [model]\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1000\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n"," 33% 125/375 [01:28<03:05,  1.35it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 8\n","\n","  0% 0/125 [00:00<?, ?it/s]\u001b[A\n","  2% 2/125 [00:00<00:16,  7.65it/s]\u001b[A\n","  2% 3/125 [00:00<00:22,  5.41it/s]\u001b[A\n","  3% 4/125 [00:00<00:25,  4.67it/s]\u001b[A\n","  4% 5/125 [00:01<00:27,  4.37it/s]\u001b[A\n","  5% 6/125 [00:01<00:28,  4.22it/s]\u001b[A\n","  6% 7/125 [00:01<00:28,  4.08it/s]\u001b[A\n","  6% 8/125 [00:01<00:29,  3.98it/s]\u001b[A\n","  7% 9/125 [00:02<00:29,  3.94it/s]\u001b[A\n","  8% 10/125 [00:02<00:29,  3.91it/s]\u001b[A\n","  9% 11/125 [00:02<00:29,  3.87it/s]\u001b[A\n"," 10% 12/125 [00:02<00:29,  3.84it/s]\u001b[A\n"," 10% 13/125 [00:03<00:29,  3.84it/s]\u001b[A\n"," 11% 14/125 [00:03<00:28,  3.87it/s]\u001b[A\n"," 12% 15/125 [00:03<00:28,  3.85it/s]\u001b[A\n"," 13% 16/125 [00:03<00:28,  3.84it/s]\u001b[A\n"," 14% 17/125 [00:04<00:28,  3.83it/s]\u001b[A\n"," 14% 18/125 [00:04<00:27,  3.84it/s]\u001b[A\n"," 15% 19/125 [00:04<00:27,  3.81it/s]\u001b[A\n"," 16% 20/125 [00:04<00:27,  3.81it/s]\u001b[A\n"," 17% 21/125 [00:05<00:27,  3.79it/s]\u001b[A\n"," 18% 22/125 [00:05<00:26,  3.82it/s]\u001b[A\n"," 18% 23/125 [00:05<00:26,  3.80it/s]\u001b[A\n"," 19% 24/125 [00:06<00:26,  3.79it/s]\u001b[A\n"," 20% 25/125 [00:06<00:26,  3.79it/s]\u001b[A\n"," 21% 26/125 [00:06<00:25,  3.82it/s]\u001b[A\n"," 22% 27/125 [00:06<00:25,  3.81it/s]\u001b[A\n"," 22% 28/125 [00:07<00:25,  3.80it/s]\u001b[A\n"," 23% 29/125 [00:07<00:25,  3.77it/s]\u001b[A\n"," 24% 30/125 [00:07<00:25,  3.79it/s]\u001b[A\n"," 25% 31/125 [00:07<00:24,  3.79it/s]\u001b[A\n"," 26% 32/125 [00:08<00:24,  3.77it/s]\u001b[A\n"," 26% 33/125 [00:08<00:24,  3.78it/s]\u001b[A\n"," 27% 34/125 [00:08<00:23,  3.80it/s]\u001b[A\n"," 28% 35/125 [00:08<00:23,  3.79it/s]\u001b[A\n"," 29% 36/125 [00:09<00:23,  3.78it/s]\u001b[A\n"," 30% 37/125 [00:09<00:23,  3.78it/s]\u001b[A\n"," 30% 38/125 [00:09<00:22,  3.79it/s]\u001b[A\n"," 31% 39/125 [00:09<00:22,  3.79it/s]\u001b[A\n"," 32% 40/125 [00:10<00:22,  3.77it/s]\u001b[A\n"," 33% 41/125 [00:10<00:22,  3.79it/s]\u001b[A\n"," 34% 42/125 [00:10<00:21,  3.80it/s]\u001b[A\n"," 34% 43/125 [00:11<00:21,  3.79it/s]\u001b[A\n"," 35% 44/125 [00:11<00:21,  3.79it/s]\u001b[A\n"," 36% 45/125 [00:11<00:21,  3.79it/s]\u001b[A\n"," 37% 46/125 [00:11<00:20,  3.80it/s]\u001b[A\n"," 38% 47/125 [00:12<00:20,  3.79it/s]\u001b[A\n"," 38% 48/125 [00:12<00:20,  3.78it/s]\u001b[A\n"," 39% 49/125 [00:12<00:20,  3.78it/s]\u001b[A\n"," 40% 50/125 [00:12<00:19,  3.79it/s]\u001b[A\n"," 41% 51/125 [00:13<00:19,  3.78it/s]\u001b[A\n"," 42% 52/125 [00:13<00:19,  3.78it/s]\u001b[A\n"," 42% 53/125 [00:13<00:19,  3.78it/s]\u001b[A\n"," 43% 54/125 [00:13<00:18,  3.79it/s]\u001b[A\n"," 44% 55/125 [00:14<00:18,  3.78it/s]\u001b[A\n"," 45% 56/125 [00:14<00:18,  3.79it/s]\u001b[A\n"," 46% 57/125 [00:14<00:17,  3.78it/s]\u001b[A\n"," 46% 58/125 [00:14<00:17,  3.78it/s]\u001b[A\n"," 47% 59/125 [00:15<00:17,  3.77it/s]\u001b[A\n"," 48% 60/125 [00:15<00:17,  3.76it/s]\u001b[A\n"," 49% 61/125 [00:15<00:17,  3.76it/s]\u001b[A\n"," 50% 62/125 [00:16<00:16,  3.78it/s]\u001b[A\n"," 50% 63/125 [00:16<00:16,  3.76it/s]\u001b[A\n"," 51% 64/125 [00:16<00:16,  3.76it/s]\u001b[A\n"," 52% 65/125 [00:16<00:16,  3.73it/s]\u001b[A\n"," 53% 66/125 [00:17<00:15,  3.74it/s]\u001b[A\n"," 54% 67/125 [00:17<00:15,  3.73it/s]\u001b[A\n"," 54% 68/125 [00:17<00:15,  3.75it/s]\u001b[A\n"," 55% 69/125 [00:17<00:15,  3.73it/s]\u001b[A\n"," 56% 70/125 [00:18<00:14,  3.73it/s]\u001b[A\n"," 57% 71/125 [00:18<00:14,  3.73it/s]\u001b[A\n"," 58% 72/125 [00:18<00:14,  3.74it/s]\u001b[A\n"," 58% 73/125 [00:19<00:13,  3.73it/s]\u001b[A\n"," 59% 74/125 [00:19<00:13,  3.73it/s]\u001b[A\n"," 60% 75/125 [00:19<00:13,  3.73it/s]\u001b[A\n"," 61% 76/125 [00:19<00:13,  3.73it/s]\u001b[A\n"," 62% 77/125 [00:20<00:12,  3.72it/s]\u001b[A\n"," 62% 78/125 [00:20<00:12,  3.74it/s]\u001b[A\n"," 63% 79/125 [00:20<00:12,  3.73it/s]\u001b[A\n"," 64% 80/125 [00:20<00:12,  3.73it/s]\u001b[A\n"," 65% 81/125 [00:21<00:11,  3.71it/s]\u001b[A\n"," 66% 82/125 [00:21<00:11,  3.72it/s]\u001b[A\n"," 66% 83/125 [00:21<00:11,  3.70it/s]\u001b[A\n"," 67% 84/125 [00:21<00:11,  3.71it/s]\u001b[A\n"," 68% 85/125 [00:22<00:10,  3.71it/s]\u001b[A\n"," 69% 86/125 [00:22<00:10,  3.70it/s]\u001b[A\n"," 70% 87/125 [00:22<00:10,  3.71it/s]\u001b[A\n"," 70% 88/125 [00:23<00:09,  3.73it/s]\u001b[A\n"," 71% 89/125 [00:23<00:09,  3.72it/s]\u001b[A\n"," 72% 90/125 [00:23<00:09,  3.68it/s]\u001b[A\n"," 73% 91/125 [00:23<00:09,  3.70it/s]\u001b[A\n"," 74% 92/125 [00:24<00:08,  3.72it/s]\u001b[A\n"," 74% 93/125 [00:24<00:08,  3.70it/s]\u001b[A\n"," 75% 94/125 [00:24<00:08,  3.69it/s]\u001b[A\n"," 76% 95/125 [00:24<00:08,  3.70it/s]\u001b[A\n"," 77% 96/125 [00:25<00:07,  3.70it/s]\u001b[A\n"," 78% 97/125 [00:25<00:07,  3.70it/s]\u001b[A\n"," 78% 98/125 [00:25<00:07,  3.69it/s]\u001b[A\n"," 79% 99/125 [00:26<00:07,  3.70it/s]\u001b[A\n"," 80% 100/125 [00:26<00:06,  3.70it/s]\u001b[A\n"," 81% 101/125 [00:26<00:06,  3.67it/s]\u001b[A\n"," 82% 102/125 [00:26<00:06,  3.69it/s]\u001b[A\n"," 82% 103/125 [00:27<00:05,  3.69it/s]\u001b[A\n"," 83% 104/125 [00:27<00:05,  3.68it/s]\u001b[A\n"," 84% 105/125 [00:27<00:05,  3.68it/s]\u001b[A\n"," 85% 106/125 [00:27<00:05,  3.67it/s]\u001b[A\n"," 86% 107/125 [00:28<00:04,  3.68it/s]\u001b[A\n"," 86% 108/125 [00:28<00:04,  3.65it/s]\u001b[A\n"," 87% 109/125 [00:28<00:04,  3.66it/s]\u001b[A\n"," 88% 110/125 [00:29<00:04,  3.66it/s]\u001b[A\n"," 89% 111/125 [00:29<00:03,  3.65it/s]\u001b[A\n"," 90% 112/125 [00:29<00:03,  3.65it/s]\u001b[A\n"," 90% 113/125 [00:29<00:03,  3.66it/s]\u001b[A\n"," 91% 114/125 [00:30<00:03,  3.66it/s]\u001b[A\n"," 92% 115/125 [00:30<00:02,  3.66it/s]\u001b[A\n"," 93% 116/125 [00:30<00:02,  3.66it/s]\u001b[A\n"," 94% 117/125 [00:30<00:02,  3.66it/s]\u001b[A\n"," 94% 118/125 [00:31<00:01,  3.66it/s]\u001b[A\n"," 95% 119/125 [00:31<00:01,  3.64it/s]\u001b[A\n"," 96% 120/125 [00:31<00:01,  3.65it/s]\u001b[A\n"," 97% 121/125 [00:32<00:01,  3.64it/s]\u001b[A\n"," 98% 122/125 [00:32<00:00,  3.64it/s]\u001b[A\n"," 98% 123/125 [00:32<00:00,  3.64it/s]\u001b[A\n"," 99% 124/125 [00:32<00:00,  3.64it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.1888095140457153, 'eval_accuracy': 0.473, 'eval_runtime': 33.405, 'eval_samples_per_second': 29.936, 'eval_steps_per_second': 3.742, 'epoch': 1.0}\n"," 33% 125/375 [02:01<03:05,  1.35it/s]\n","100% 125/125 [00:33<00:00,  3.64it/s]\u001b[A\n"," 67% 250/375 [03:36<01:34,  1.32it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 8\n","\n","  0% 0/125 [00:00<?, ?it/s]\u001b[A\n","  2% 2/125 [00:00<00:17,  7.20it/s]\u001b[A\n","  2% 3/125 [00:00<00:23,  5.12it/s]\u001b[A\n","  3% 4/125 [00:00<00:27,  4.43it/s]\u001b[A\n","  4% 5/125 [00:01<00:28,  4.17it/s]\u001b[A\n","  5% 6/125 [00:01<00:30,  3.94it/s]\u001b[A\n","  6% 7/125 [00:01<00:30,  3.83it/s]\u001b[A\n","  6% 8/125 [00:01<00:30,  3.79it/s]\u001b[A\n","  7% 9/125 [00:02<00:30,  3.77it/s]\u001b[A\n","  8% 10/125 [00:02<00:31,  3.70it/s]\u001b[A\n","  9% 11/125 [00:02<00:30,  3.68it/s]\u001b[A\n"," 10% 12/125 [00:03<00:30,  3.69it/s]\u001b[A\n"," 10% 13/125 [00:03<00:30,  3.67it/s]\u001b[A\n"," 11% 14/125 [00:03<00:30,  3.65it/s]\u001b[A\n"," 12% 15/125 [00:03<00:30,  3.65it/s]\u001b[A\n"," 13% 16/125 [00:04<00:29,  3.67it/s]\u001b[A\n"," 14% 17/125 [00:04<00:29,  3.66it/s]\u001b[A\n"," 14% 18/125 [00:04<00:29,  3.66it/s]\u001b[A\n"," 15% 19/125 [00:04<00:28,  3.67it/s]\u001b[A\n"," 16% 20/125 [00:05<00:28,  3.66it/s]\u001b[A\n"," 17% 21/125 [00:05<00:28,  3.66it/s]\u001b[A\n"," 18% 22/125 [00:05<00:28,  3.65it/s]\u001b[A\n"," 18% 23/125 [00:06<00:27,  3.65it/s]\u001b[A\n"," 19% 24/125 [00:06<00:27,  3.64it/s]\u001b[A\n"," 20% 25/125 [00:06<00:27,  3.64it/s]\u001b[A\n"," 21% 26/125 [00:06<00:27,  3.66it/s]\u001b[A\n"," 22% 27/125 [00:07<00:26,  3.65it/s]\u001b[A\n"," 22% 28/125 [00:07<00:26,  3.64it/s]\u001b[A\n"," 23% 29/125 [00:07<00:26,  3.64it/s]\u001b[A\n"," 24% 30/125 [00:07<00:25,  3.66it/s]\u001b[A\n"," 25% 31/125 [00:08<00:25,  3.65it/s]\u001b[A\n"," 26% 32/125 [00:08<00:25,  3.64it/s]\u001b[A\n"," 26% 33/125 [00:08<00:25,  3.65it/s]\u001b[A\n"," 27% 34/125 [00:09<00:24,  3.66it/s]\u001b[A\n"," 28% 35/125 [00:09<00:24,  3.66it/s]\u001b[A\n"," 29% 36/125 [00:09<00:24,  3.66it/s]\u001b[A\n"," 30% 37/125 [00:09<00:24,  3.64it/s]\u001b[A\n"," 30% 38/125 [00:10<00:23,  3.66it/s]\u001b[A\n"," 31% 39/125 [00:10<00:23,  3.65it/s]\u001b[A\n"," 32% 40/125 [00:10<00:23,  3.66it/s]\u001b[A\n"," 33% 41/125 [00:10<00:22,  3.66it/s]\u001b[A\n"," 34% 42/125 [00:11<00:22,  3.66it/s]\u001b[A\n"," 34% 43/125 [00:11<00:22,  3.65it/s]\u001b[A\n"," 35% 44/125 [00:11<00:22,  3.66it/s]\u001b[A\n"," 36% 45/125 [00:12<00:21,  3.65it/s]\u001b[A\n"," 37% 46/125 [00:12<00:21,  3.66it/s]\u001b[A\n"," 38% 47/125 [00:12<00:21,  3.66it/s]\u001b[A\n"," 38% 48/125 [00:12<00:21,  3.65it/s]\u001b[A\n"," 39% 49/125 [00:13<00:20,  3.65it/s]\u001b[A\n"," 40% 50/125 [00:13<00:20,  3.65it/s]\u001b[A\n"," 41% 51/125 [00:13<00:20,  3.66it/s]\u001b[A\n"," 42% 52/125 [00:13<00:19,  3.66it/s]\u001b[A\n"," 42% 53/125 [00:14<00:19,  3.66it/s]\u001b[A\n"," 43% 54/125 [00:14<00:19,  3.66it/s]\u001b[A\n"," 44% 55/125 [00:14<00:19,  3.66it/s]\u001b[A\n"," 45% 56/125 [00:15<00:18,  3.66it/s]\u001b[A\n"," 46% 57/125 [00:15<00:18,  3.67it/s]\u001b[A\n"," 46% 58/125 [00:15<00:18,  3.67it/s]\u001b[A\n"," 47% 59/125 [00:15<00:17,  3.68it/s]\u001b[A\n"," 48% 60/125 [00:16<00:17,  3.66it/s]\u001b[A\n"," 49% 61/125 [00:16<00:17,  3.65it/s]\u001b[A\n"," 50% 62/125 [00:16<00:17,  3.67it/s]\u001b[A\n"," 50% 63/125 [00:16<00:16,  3.67it/s]\u001b[A\n"," 51% 64/125 [00:17<00:16,  3.67it/s]\u001b[A\n"," 52% 65/125 [00:17<00:16,  3.65it/s]\u001b[A\n"," 53% 66/125 [00:17<00:16,  3.66it/s]\u001b[A\n"," 54% 67/125 [00:18<00:15,  3.66it/s]\u001b[A\n"," 54% 68/125 [00:18<00:15,  3.67it/s]\u001b[A\n"," 55% 69/125 [00:18<00:15,  3.65it/s]\u001b[A\n"," 56% 70/125 [00:18<00:14,  3.67it/s]\u001b[A\n"," 57% 71/125 [00:19<00:14,  3.66it/s]\u001b[A\n"," 58% 72/125 [00:19<00:14,  3.67it/s]\u001b[A\n"," 58% 73/125 [00:19<00:14,  3.65it/s]\u001b[A\n"," 59% 74/125 [00:19<00:13,  3.66it/s]\u001b[A\n"," 60% 75/125 [00:20<00:13,  3.66it/s]\u001b[A\n"," 61% 76/125 [00:20<00:13,  3.65it/s]\u001b[A\n"," 62% 77/125 [00:20<00:13,  3.66it/s]\u001b[A\n"," 62% 78/125 [00:21<00:12,  3.66it/s]\u001b[A\n"," 63% 79/125 [00:21<00:12,  3.67it/s]\u001b[A\n"," 64% 80/125 [00:21<00:12,  3.66it/s]\u001b[A\n"," 65% 81/125 [00:21<00:11,  3.67it/s]\u001b[A\n"," 66% 82/125 [00:22<00:11,  3.67it/s]\u001b[A\n"," 66% 83/125 [00:22<00:11,  3.67it/s]\u001b[A\n"," 67% 84/125 [00:22<00:11,  3.66it/s]\u001b[A\n"," 68% 85/125 [00:22<00:10,  3.67it/s]\u001b[A\n"," 69% 86/125 [00:23<00:10,  3.67it/s]\u001b[A\n"," 70% 87/125 [00:23<00:10,  3.67it/s]\u001b[A\n"," 70% 88/125 [00:23<00:10,  3.67it/s]\u001b[A\n"," 71% 89/125 [00:24<00:09,  3.67it/s]\u001b[A\n"," 72% 90/125 [00:24<00:09,  3.67it/s]\u001b[A\n"," 73% 91/125 [00:24<00:09,  3.68it/s]\u001b[A\n"," 74% 92/125 [00:24<00:08,  3.67it/s]\u001b[A\n"," 74% 93/125 [00:25<00:08,  3.68it/s]\u001b[A\n"," 75% 94/125 [00:25<00:08,  3.68it/s]\u001b[A\n"," 76% 95/125 [00:25<00:08,  3.68it/s]\u001b[A\n"," 77% 96/125 [00:25<00:07,  3.68it/s]\u001b[A\n"," 78% 97/125 [00:26<00:07,  3.68it/s]\u001b[A\n"," 78% 98/125 [00:26<00:07,  3.69it/s]\u001b[A\n"," 79% 99/125 [00:26<00:07,  3.69it/s]\u001b[A\n"," 80% 100/125 [00:27<00:06,  3.68it/s]\u001b[A\n"," 81% 101/125 [00:27<00:06,  3.68it/s]\u001b[A\n"," 82% 102/125 [00:27<00:06,  3.70it/s]\u001b[A\n"," 82% 103/125 [00:27<00:05,  3.69it/s]\u001b[A\n"," 83% 104/125 [00:28<00:05,  3.69it/s]\u001b[A\n"," 84% 105/125 [00:28<00:05,  3.69it/s]\u001b[A\n"," 85% 106/125 [00:28<00:05,  3.69it/s]\u001b[A\n"," 86% 107/125 [00:28<00:04,  3.69it/s]\u001b[A\n"," 86% 108/125 [00:29<00:04,  3.68it/s]\u001b[A\n"," 87% 109/125 [00:29<00:04,  3.68it/s]\u001b[A\n"," 88% 110/125 [00:29<00:04,  3.67it/s]\u001b[A\n"," 89% 111/125 [00:30<00:03,  3.67it/s]\u001b[A\n"," 90% 112/125 [00:30<00:03,  3.68it/s]\u001b[A\n"," 90% 113/125 [00:30<00:03,  3.67it/s]\u001b[A\n"," 91% 114/125 [00:30<00:02,  3.68it/s]\u001b[A\n"," 92% 115/125 [00:31<00:02,  3.68it/s]\u001b[A\n"," 93% 116/125 [00:31<00:02,  3.69it/s]\u001b[A\n"," 94% 117/125 [00:31<00:02,  3.68it/s]\u001b[A\n"," 94% 118/125 [00:31<00:01,  3.70it/s]\u001b[A\n"," 95% 119/125 [00:32<00:01,  3.70it/s]\u001b[A\n"," 96% 120/125 [00:32<00:01,  3.69it/s]\u001b[A\n"," 97% 121/125 [00:32<00:01,  3.68it/s]\u001b[A\n"," 98% 122/125 [00:33<00:00,  3.69it/s]\u001b[A\n"," 98% 123/125 [00:33<00:00,  3.69it/s]\u001b[A\n"," 99% 124/125 [00:33<00:00,  3.68it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.0772262811660767, 'eval_accuracy': 0.55, 'eval_runtime': 34.118, 'eval_samples_per_second': 29.31, 'eval_steps_per_second': 3.664, 'epoch': 2.0}\n"," 67% 250/375 [04:10<01:34,  1.32it/s]\n","100% 125/125 [00:33<00:00,  3.68it/s]\u001b[A\n","100% 375/375 [05:44<00:00,  1.32it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 8\n","\n","  0% 0/125 [00:00<?, ?it/s]\u001b[A\n","  2% 2/125 [00:00<00:17,  7.22it/s]\u001b[A\n","  2% 3/125 [00:00<00:23,  5.14it/s]\u001b[A\n","  3% 4/125 [00:00<00:26,  4.48it/s]\u001b[A\n","  4% 5/125 [00:01<00:28,  4.18it/s]\u001b[A\n","  5% 6/125 [00:01<00:29,  3.97it/s]\u001b[A\n","  6% 7/125 [00:01<00:30,  3.83it/s]\u001b[A\n","  6% 8/125 [00:01<00:30,  3.80it/s]\u001b[A\n","  7% 9/125 [00:02<00:30,  3.76it/s]\u001b[A\n","  8% 10/125 [00:02<00:30,  3.71it/s]\u001b[A\n","  9% 11/125 [00:02<00:30,  3.68it/s]\u001b[A\n"," 10% 12/125 [00:03<00:30,  3.70it/s]\u001b[A\n"," 10% 13/125 [00:03<00:30,  3.69it/s]\u001b[A\n"," 11% 14/125 [00:03<00:30,  3.66it/s]\u001b[A\n"," 12% 15/125 [00:03<00:30,  3.66it/s]\u001b[A\n"," 13% 16/125 [00:04<00:29,  3.67it/s]\u001b[A\n"," 14% 17/125 [00:04<00:29,  3.65it/s]\u001b[A\n"," 14% 18/125 [00:04<00:29,  3.65it/s]\u001b[A\n"," 15% 19/125 [00:04<00:28,  3.66it/s]\u001b[A\n"," 16% 20/125 [00:05<00:28,  3.66it/s]\u001b[A\n"," 17% 21/125 [00:05<00:28,  3.65it/s]\u001b[A\n"," 18% 22/125 [00:05<00:28,  3.65it/s]\u001b[A\n"," 18% 23/125 [00:06<00:28,  3.64it/s]\u001b[A\n"," 19% 24/125 [00:06<00:27,  3.64it/s]\u001b[A\n"," 20% 25/125 [00:06<00:27,  3.64it/s]\u001b[A\n"," 21% 26/125 [00:06<00:27,  3.65it/s]\u001b[A\n"," 22% 27/125 [00:07<00:26,  3.64it/s]\u001b[A\n"," 22% 28/125 [00:07<00:26,  3.63it/s]\u001b[A\n"," 23% 29/125 [00:07<00:26,  3.65it/s]\u001b[A\n"," 24% 30/125 [00:07<00:25,  3.66it/s]\u001b[A\n"," 25% 31/125 [00:08<00:25,  3.66it/s]\u001b[A\n"," 26% 32/125 [00:08<00:25,  3.63it/s]\u001b[A\n"," 26% 33/125 [00:08<00:25,  3.66it/s]\u001b[A\n"," 27% 34/125 [00:09<00:24,  3.66it/s]\u001b[A\n"," 28% 35/125 [00:09<00:24,  3.65it/s]\u001b[A\n"," 29% 36/125 [00:09<00:24,  3.64it/s]\u001b[A\n"," 30% 37/125 [00:09<00:24,  3.66it/s]\u001b[A\n"," 30% 38/125 [00:10<00:23,  3.66it/s]\u001b[A\n"," 31% 39/125 [00:10<00:23,  3.66it/s]\u001b[A\n"," 32% 40/125 [00:10<00:23,  3.65it/s]\u001b[A\n"," 33% 41/125 [00:10<00:22,  3.67it/s]\u001b[A\n"," 34% 42/125 [00:11<00:22,  3.66it/s]\u001b[A\n"," 34% 43/125 [00:11<00:22,  3.64it/s]\u001b[A\n"," 35% 44/125 [00:11<00:22,  3.66it/s]\u001b[A\n"," 36% 45/125 [00:12<00:21,  3.66it/s]\u001b[A\n"," 37% 46/125 [00:12<00:21,  3.66it/s]\u001b[A\n"," 38% 47/125 [00:12<00:21,  3.66it/s]\u001b[A\n"," 38% 48/125 [00:12<00:21,  3.65it/s]\u001b[A\n"," 39% 49/125 [00:13<00:20,  3.66it/s]\u001b[A\n"," 40% 50/125 [00:13<00:20,  3.66it/s]\u001b[A\n"," 41% 51/125 [00:13<00:20,  3.66it/s]\u001b[A\n"," 42% 52/125 [00:13<00:19,  3.67it/s]\u001b[A\n"," 42% 53/125 [00:14<00:19,  3.67it/s]\u001b[A\n"," 43% 54/125 [00:14<00:19,  3.68it/s]\u001b[A\n"," 44% 55/125 [00:14<00:19,  3.67it/s]\u001b[A\n"," 45% 56/125 [00:15<00:18,  3.68it/s]\u001b[A\n"," 46% 57/125 [00:15<00:18,  3.65it/s]\u001b[A\n"," 46% 58/125 [00:15<00:18,  3.67it/s]\u001b[A\n"," 47% 59/125 [00:15<00:18,  3.66it/s]\u001b[A\n"," 48% 60/125 [00:16<00:17,  3.67it/s]\u001b[A\n"," 49% 61/125 [00:16<00:17,  3.65it/s]\u001b[A\n"," 50% 62/125 [00:16<00:17,  3.66it/s]\u001b[A\n"," 50% 63/125 [00:16<00:16,  3.66it/s]\u001b[A\n"," 51% 64/125 [00:17<00:16,  3.66it/s]\u001b[A\n"," 52% 65/125 [00:17<00:16,  3.66it/s]\u001b[A\n"," 53% 66/125 [00:17<00:16,  3.65it/s]\u001b[A\n"," 54% 67/125 [00:18<00:15,  3.66it/s]\u001b[A\n"," 54% 68/125 [00:18<00:15,  3.64it/s]\u001b[A\n"," 55% 69/125 [00:18<00:15,  3.66it/s]\u001b[A\n"," 56% 70/125 [00:18<00:15,  3.66it/s]\u001b[A\n"," 57% 71/125 [00:19<00:14,  3.66it/s]\u001b[A\n"," 58% 72/125 [00:19<00:14,  3.66it/s]\u001b[A\n"," 58% 73/125 [00:19<00:14,  3.66it/s]\u001b[A\n"," 59% 74/125 [00:19<00:13,  3.66it/s]\u001b[A\n"," 60% 75/125 [00:20<00:13,  3.65it/s]\u001b[A\n"," 61% 76/125 [00:20<00:13,  3.65it/s]\u001b[A\n"," 62% 77/125 [00:20<00:13,  3.66it/s]\u001b[A\n"," 62% 78/125 [00:21<00:12,  3.65it/s]\u001b[A\n"," 63% 79/125 [00:21<00:12,  3.65it/s]\u001b[A\n"," 64% 80/125 [00:21<00:12,  3.66it/s]\u001b[A\n"," 65% 81/125 [00:21<00:12,  3.66it/s]\u001b[A\n"," 66% 82/125 [00:22<00:11,  3.65it/s]\u001b[A\n"," 66% 83/125 [00:22<00:11,  3.65it/s]\u001b[A\n"," 67% 84/125 [00:22<00:11,  3.65it/s]\u001b[A\n"," 68% 85/125 [00:22<00:10,  3.66it/s]\u001b[A\n"," 69% 86/125 [00:23<00:10,  3.65it/s]\u001b[A\n"," 70% 87/125 [00:23<00:10,  3.64it/s]\u001b[A\n"," 70% 88/125 [00:23<00:10,  3.67it/s]\u001b[A\n"," 71% 89/125 [00:24<00:09,  3.67it/s]\u001b[A\n"," 72% 90/125 [00:24<00:09,  3.66it/s]\u001b[A\n"," 73% 91/125 [00:24<00:09,  3.65it/s]\u001b[A\n"," 74% 92/125 [00:24<00:08,  3.67it/s]\u001b[A\n"," 74% 93/125 [00:25<00:08,  3.67it/s]\u001b[A\n"," 75% 94/125 [00:25<00:08,  3.66it/s]\u001b[A\n"," 76% 95/125 [00:25<00:08,  3.67it/s]\u001b[A\n"," 77% 96/125 [00:25<00:07,  3.67it/s]\u001b[A\n"," 78% 97/125 [00:26<00:07,  3.67it/s]\u001b[A\n"," 78% 98/125 [00:26<00:07,  3.66it/s]\u001b[A\n"," 79% 99/125 [00:26<00:07,  3.67it/s]\u001b[A\n"," 80% 100/125 [00:27<00:06,  3.67it/s]\u001b[A\n"," 81% 101/125 [00:27<00:06,  3.67it/s]\u001b[A\n"," 82% 102/125 [00:27<00:06,  3.67it/s]\u001b[A\n"," 82% 103/125 [00:27<00:06,  3.66it/s]\u001b[A\n"," 83% 104/125 [00:28<00:05,  3.68it/s]\u001b[A\n"," 84% 105/125 [00:28<00:05,  3.67it/s]\u001b[A\n"," 85% 106/125 [00:28<00:05,  3.67it/s]\u001b[A\n"," 86% 107/125 [00:28<00:04,  3.67it/s]\u001b[A\n"," 86% 108/125 [00:29<00:04,  3.67it/s]\u001b[A\n"," 87% 109/125 [00:29<00:04,  3.66it/s]\u001b[A\n"," 88% 110/125 [00:29<00:04,  3.66it/s]\u001b[A\n"," 89% 111/125 [00:30<00:03,  3.67it/s]\u001b[A\n"," 90% 112/125 [00:30<00:03,  3.65it/s]\u001b[A\n"," 90% 113/125 [00:30<00:03,  3.68it/s]\u001b[A\n"," 91% 114/125 [00:30<00:03,  3.67it/s]\u001b[A\n"," 92% 115/125 [00:31<00:02,  3.66it/s]\u001b[A\n"," 93% 116/125 [00:31<00:02,  3.66it/s]\u001b[A\n"," 94% 117/125 [00:31<00:02,  3.67it/s]\u001b[A\n"," 94% 118/125 [00:31<00:01,  3.67it/s]\u001b[A\n"," 95% 119/125 [00:32<00:01,  3.66it/s]\u001b[A\n"," 96% 120/125 [00:32<00:01,  3.67it/s]\u001b[A\n"," 97% 121/125 [00:32<00:01,  3.67it/s]\u001b[A\n"," 98% 122/125 [00:33<00:00,  3.67it/s]\u001b[A\n"," 98% 123/125 [00:33<00:00,  3.65it/s]\u001b[A\n"," 99% 124/125 [00:33<00:00,  3.67it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 1.0230867862701416, 'eval_accuracy': 0.584, 'eval_runtime': 34.1764, 'eval_samples_per_second': 29.26, 'eval_steps_per_second': 3.657, 'epoch': 3.0}\n","100% 375/375 [06:18<00:00,  1.32it/s]\n","100% 125/125 [00:33<00:00,  3.67it/s]\u001b[A\n","                                     \u001b[A\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 379.1746, 'train_samples_per_second': 7.912, 'train_steps_per_second': 0.989, 'train_loss': 1.036133056640625, 'epoch': 3.0}\n","100% 375/375 [06:18<00:00,  1.01s/it]\n","2022-07-06 16:26:46,150 - kedro.io.data_catalog - INFO - Saving data to `model` (PickleDataSet)...\n","2022-07-06 16:26:47,794 - kedro.runner.sequential_runner - INFO - Completed 4 out of 4 tasks\n","2022-07-06 16:26:47,795 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.\n","2022-07-06 16:26:47,795 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Hgy2iG2HYA2B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make catalog available"],"metadata":{"id":"rKzZzihAYDWE"}},{"cell_type":"code","source":["%load_ext kedro.extras.extensions.ipython\n","%reload_kedro /content/gdrive/MyDrive/Colab Notebooks/myhuggingface/sequenceclassification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPo9mBA6Xirl","executionInfo":{"status":"ok","timestamp":1657125506964,"user_tz":-120,"elapsed":701,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"bfc9a3a7-d38d-4658-aa2b-d73925ac2138"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["The kedro.extras.extensions.ipython extension is already loaded. To reload it, use:\n","  %reload_ext kedro.extras.extensions.ipython\n","2022-07-06 16:38:26,142 - kedro.extras.extensions.ipython - INFO - Updated path to Kedro project: /content/gdrive/MyDrive/Colab Notebooks/myhuggingface/sequenceclassification\n","2022-07-06 16:38:26,303 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n","2022-07-06 16:38:26,333 - kedro.framework.session.session - WARNING - Unable to git describe /content/gdrive/MyDrive/Colab Notebooks/myhuggingface/sequenceclassification\n","2022-07-06 16:38:26,398 - kedro.extras.extensions.ipython - INFO - ** Kedro project sequenceClassification\n","2022-07-06 16:38:26,403 - kedro.extras.extensions.ipython - INFO - Defined global variable `context`, `session`, `catalog` and `pipelines`\n"]}]},{"cell_type":"code","source":["model = catalog.load('model')\n","small_eval_dataset = catalog.load('small_eval_dataset')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeaOYfGVX2FJ","executionInfo":{"status":"ok","timestamp":1657125683417,"user_tz":-120,"elapsed":1131,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"2600a4f0-3ae3-48dd-f2b8-8b40bb31b174"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-07-06 16:41:22,149 - kedro.io.data_catalog - INFO - Loading data from `model` (PickleDataSet)...\n","2022-07-06 16:41:22,988 - kedro.io.data_catalog - INFO - Loading data from `small_eval_dataset` (PickleDataSet)...\n"]}]},{"cell_type":"markdown","source":["# Put data into dataloader"],"metadata":{"id":"OookwhL5Y6VN"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)\n","\n","list(eval_dataloader)[0]"],"metadata":{"id":"xlDEIUHjYNVr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Calc metrics by hand"],"metadata":{"id":"u4i9Poj1YYwn"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XYWe5QqZCSI","executionInfo":{"status":"ok","timestamp":1657125760301,"user_tz":-120,"elapsed":9,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"ab551dd3-235b-4a76-9cc4-3eb09369ef7f"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul  6 16:42:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   53C    P0    27W /  70W |   1462MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)"],"metadata":{"id":"8gQHu3j5anPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_metric\n","metric = load_metric(\"accuracy\")\n","model.eval()\n","for batch in eval_dataloader:\n","    print(batch)\n","\n","    batch = {k: v for k, v in batch.items() if k in [ 'input_ids']}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    logits = outputs.logits\n","    predictions = torch.argmax(logits, dim=-1)\n","    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","metric.compute()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"E-5VXLvDYbDA","executionInfo":{"status":"error","timestamp":1657126842394,"user_tz":-120,"elapsed":1250,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"de853f52-6455-4e2d-a15d-fe797aa23a34"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["{'label': tensor([2, 4, 1, 4, 3, 4, 2, 3]), 'text': ['Kabuto is your run-of-the-mill Japanese Steakhouse. Different stations with chefs slinging shrimp tails around the communal dining areas like it\\'s a lunchtime magic show. Always a plethora of laughs and gags going around the group. \\\\n\\\\nThis place is great for lunch. $9 and 30 minutes and you\\'re out the door. Uhhh...If I\\'m craving a salad with ginger dressing, which I always am, (you do too. admit it) fried rice, steak, shrimp and white sauce (DUDE) then Kabuto is king of lunch options in my book. Always super clean and full of kindhearted staff. The parking lot is super difficult to get in and out of though. 51 traffic at lunch is a beast. Good luck getting stuck behind someone trying to cut across traffic at 12pm on a weekday. It\\'s murder. This place would greatly benefit from another exit/entrance or a stoplight. Here\\'s hoping....\\\\n\\\\nYou can\\'t really shake a stick at balanced lunch when you can have soup or a salad, veggies, fried rice and a choice of a protein for under $10 and be back out the door and headed back to the office or meeting. Glad to see these guys have taken this into account. Though, you should know that the $10 offering mostly comes in the protein department. Some may require more steak or chicken, which can be sparse. \\\\n\\\\nService is always quick and friendly. They do a wonderful job of memorizing orders. Rarely has it come to pass that my order has been mal-delivered. Quick on refills and I love that they always offer a to-go beverage. \\\\\"Why, yes! I would love a diet coke to go! How thoughtful!\\\\\" Pretty much always my thought process. \\\\n\\\\nThis place also does full dinner options and has sushi. Neither of which I have tried to date, but would happily oblige if the option was presented. \\\\n\\\\nThanks for the quick and entertaining lunch/service, Kabuto!', 'Visiting here for 10 days and staying in a condo\\\\nDriving around and found this place\\\\nAte here 2x ( Lunch + Dinner)\\\\nFood was fresh + Tasty\\\\nSushi was great for the price\\\\nShrimp OK but about the same as other buffets\\\\nSesame balls were lite and great\\\\nFor desert they had a coffee taramisu which was rather good', 'Terrible terrible food', 'This is a beautiful theatre with a gorgeous glass front which is great for watching the world go buy while having a coffee.\\\\n\\\\nI have fond memories of coming to this theatre to see the ballet since I was very young. I rather distinctly remember on my 9th birthday vomiting on the stairs during a performance of Cinderella. Ahh memories.\\\\n\\\\nBut this theatre really is lovely. Its the sort of theatre that you get a little dressed up to go to, like people used to do back in the day. I was lucky enough to see a stunning performance of the Nutcracker here in January, which obviously is mostly attributed to Scottish Ballet but the theatre played a huge role also. Everything from the sound to the lighting was fantastic and it really was a magical evening. \\\\n\\\\nThere is a number of bars for you to have a quick tipple during the interval, but you have to be quick out your seat because it gets very busy fast. \\\\n\\\\nTickets can be expensive, but it really attracts some of the better quality shows so it is worth it and it really makes for a nice evening out.', \"I don't quite get this place or why Asians love it, but it is very good :)\", \"Holy cow, their food is outstanding, but their tortillas are the best in PHX, home of the best Mexican food in the US...that is saying a lot, I know, but please check them out for yourself. I'm going back to PHX soon for the first time since moving away, and Carolina's will be my first stop. I'm salivating just writing this review. Truly awesome!!!\", 'We stayed here the night before my girlfriend\\'s flight and didn\\'t really know what to expect.  We were pleasantly surprised that it was a pretty good business hotel!  I\\'ll list the good and bad separately.\\\\n\\\\nGood:  The sheets were clean, the room was clean, the water was hot, the amenities were good for the price point and the beds were fairly comfortable.  Wifi was easy to connect to and signal was strong.\\\\n\\\\nBad:  We saw dozens of dogs in this hotel...I know people love their pets, but allowing pets in a hotel without proper fogging is just asking for flea problems, especially since most people let their pets on the bed.  Fortunately, we didn\\'t have any problems with fleas. We DID have a problem with the night staff, though.  The clerk was nice enough, but the second lady (who did the cleaning, I suppose) has a SERIOUS attitude problem.  She was very rude to my Chinese girlfriend, who doesn\\'t always pick up rapid English when it\\'s not spoken directly to her.  We also heard this unpleasant woman tell our neighboring room that \\\\\"YOU DO NOT TELL ME TO GET YOU ANYTHING.  YOU TELL THE FRONT DESK AND SHE TELLS ME TO GET THEM.  THAT IS HOW IT WORKS. \\\\\"  All in a loud, echoing voice.  \\\\n\\\\nI suppose the breakfast was just OK.  Very light on meat and heavy on cheap carbs, but it was enough to get us out of the door in the morning.  We liked this hotel, but might avoid this particular La Quinta because of that lady.  After hours of driving, we want smiles and not rude barking from a staff member that rivals the dogs that bring fleas into the rooms....\\\\n\\\\nAlso of note:  You can reserve a room with a card, but you must ALSO let them put a hold on your card for the full room amount until checkout.  You can pay cash at checkout.  This wasn\\'t explained to us until we were at the counter.', \"Stopped back by Mellow Mushroom with my mate Justin from Brew Bros. & a few of our mates Monday afternoon while pub crawling on a day off.  \\\\nFirst I must say my return trip was motivated by an immediate response from to my 1st Yelp review from Mellow Mushroom's owner Jay.  I didnt expect any reponse, much less a return so quickly. Respect for that. Great to see to someone paying such close attention to their customers.\\\\nThis can only be a good thing.\\\\nThe same draft selection as the first time around.  48 Handles.  Thats a lot of beer.  As said in my first reiview, with 48 handles I would Love to see more variety and a bit more imagination with respect to the draft beer choices, then again who would complain about a selection w/ at least 40 craft beers on tap?   Thats a real commitment. \\\\nOur bartender Madison was enthusiastic about what she was serving which in Arizona's growing craft beer community is a big plus.  On a another note, this time around the food I ordered made it out of the kitchen rather quickly.  Just a mediterainan salad, but nice.\\\\nAll said, great to see another craft beer brother join the club.  Nice to have you here.\"], 'input_ids': [tensor([101, 101, 101, 101, 101, 101, 101, 101]), tensor([14812, 19383, 12008,  1188,   146,  3930,  1284,  6682]), tensor([16442,  1303, 27788,  1110,  1274, 13991,  3523,  3537]), tensor([1186, 1111, 6434,  170,  112,  117, 1303, 1171]), tensor([1110, 1275, 2094, 2712,  189, 1147, 1103, 1118]), tensor([ 1240,  1552,   102,  4041,  2385,  2094,  1480, 11637]), tensor([1576, 1105,    0, 1114, 1243, 1110, 1196, 6737]), tensor([  118,  6218,     0,   170,  1142,  6976,  1139, 19569]), tensor([ 1104,  1107,     0, 10144,  1282,   117,  6124,  2737]), tensor([ 118,  170,    0, 2525, 1137, 1133,  112, 6077]), tensor([ 1103, 14255,     0,  1524,  1725,  1147,   188,  1114]), tensor([ 118, 2572,    0, 1134, 3141, 1106, 3043, 1139]), tensor([6159,  165,    0, 1110, 1116, 3740, 1105, 6642]), tensor([1983,  183,    0, 1632, 1567, 5878, 1238, 6193]), tensor([1457, 2137,    0, 1111, 1122, 1116,  112, 1121]), tensor([23783,  2047,     0,  2903,   117,  1132,   189,   139]), tensor([ 3255,  3970,     0,  1103,  1133,  1103,  1541, 11899]), tensor([  119,  1213,     0,  1362,  1122,  1436,  1221, 10145]), tensor([14380,  1105,     0,  1301,  1110,  1107,  1184,   119]), tensor([2930, 1276,    0, 4417, 1304,  153, 1106,  111]), tensor([1114, 1142,    0, 1229, 1363, 3048, 5363,  170]), tensor([13628,  1282,     0,  1515,   131,  3190,   119,  1374]), tensor([1116,  165,    0,  170,  114,  117, 1284, 1104]), tensor([ 188,  183,    0, 3538,  102, 1313, 1127, 1412]), tensor([ 1979,  1592,     0,   119,     0,  1104, 10287, 16195]), tensor([1158, 1566,    0,  165,    0, 1103, 1193, 6356]), tensor([23982,  1303,     0,   183,     0,  1436,  3753,  4427]), tensor([21315,   123,     0,   165,     0,  4112,  1115,  1229]), tensor([ 1213,  1775,     0,   183,     0,  2094,  1122, 11030]), tensor([ 1103,   113,     0,  2240,     0,  1107,  1108, 17872]), tensor([17022, 14557,     0,  1138,     0,  1103,   170,  1113]), tensor([ 7659, 11273,     0, 15263,     0,  1646,  2785,   170]), tensor([1877,  116,    0, 5628,    0,  119, 1363, 1285]), tensor([ 1176, 20333,     0,  1104,     0,   119,  1671,  1228]), tensor([1122,  114,    0, 1909,    0,  119, 3415,  119]), tensor([ 112,  165,    0, 1106,    0, 1115,  106,  165]), tensor([ 188,  183,    0, 1142,    0, 1110,  146,  183]), tensor([ 170, 2271,    0, 4041,    0, 2157,  112, 2271]), tensor([ 5953, 13465,     0,  1106,     0,   170,  1325, 11836]), tensor([4974, 1108,    0, 1267,    0, 1974, 2190, 1204]), tensor([3974, 4489,    0, 1103,    0,  117, 1103,  146]), tensor([ 1437,   116,     0, 10921,     0,   146,  1363,  1538]), tensor([  119, 22515,     0,  1290,     0,  1221,  1105,  1474]), tensor([10672, 13913,     0,   146,     0,   117,  2213,  1139]), tensor([  170,   165,     0,  1108,     0,  1133, 10380,  1862]), tensor([ 185,  183,    0, 1304,    0, 4268,  119, 3868]), tensor([5765, 1708,    0, 1685,    0, 4031,  165, 1108]), tensor([16426, 13148,     0,   119,     0,  1172,   183, 13241]), tensor([1104, 1182,    0,  146,    0, 1149,  165, 1118]), tensor([12375,  1108,     0,  1897,     0,  1111,   183,  1126]), tensor([ 1105,  1632,     0, 21389,     0,  3739,  2349,  5670]), tensor([21102,  1111,     0,  2676,     0,   119, 13465,  2593]), tensor([1116, 1103,    0, 1113,    0,  146,  131, 1121]), tensor([1280, 3945,    0, 1139,    0,  112, 1109, 1106]), tensor([1213,  165,    0, 5612,    0,  182, 8675, 1139]), tensor([1103,  183,    0, 5913,    0, 1280, 1127, 2198]), tensor([ 1372,  1708,     0, 26979,     0,  1171,  4044, 15821]), tensor([ 119, 8167,    0, 1158,    0, 1106,  117, 1233]), tensor([ 165, 4060,    0, 1113,    0,  153, 1103, 1643]), tensor([ 183, 1643,    0, 1103,    0, 3048, 1395, 3189]), tensor([  165, 10899,     0,  4377,     0,  3190,  1108,  1121]), tensor([  183,  1133,     0,  1219,     0,  1770,  4044, 11637]), tensor([1942, 1164,    0,  170,    0, 1111,  117, 6737]), tensor([27516,  1103,     0,  2099,     0,  1103,  1103, 19569]), tensor([1282, 1269,    0, 1104,    0, 1148, 1447, 2737]), tensor([ 1110,  1112,     0, 24139,     0,  1159,  1108,  6077]), tensor([1632, 1168,    0,  119,    0, 1290, 2633,  112]), tensor([1111,  171,    0, 7066,    0, 2232,  117,  188]), tensor([5953, 9435,    0, 1324,    0, 1283, 1103, 3172]), tensor([  119,  6248,     0,  5628,     0,   117, 23134,  5525]), tensor([ 109,  165,    0,  119,    0, 1105, 1127,  119]), tensor([ 130,  183,    0,  165,    0, 2938, 1363,  146]), tensor([1105, 1708,    0,  183,    0,  112, 1111, 1238]), tensor([1476, 1279,    0,  165,    0,  188, 1103, 1204]), tensor([ 1904, 16470,     0,   183,     0,  1209,  3945,  5363]), tensor([1105, 7318,    0, 2064,    0, 1129, 1553, 1251]), tensor([1128, 1127,    0, 3818,    0, 1139, 1105, 1231]), tensor([ 112, 4941,    0, 1142,    0, 1148, 1103, 5674]), tensor([ 1231,  1162,     0,  4041,     0,  1831,  9884, 19054]), tensor([1149, 1105,    0, 1541,    0,  119, 1127,  117]), tensor([1103, 1632,    0, 1110,    0,  146, 6751, 1277]), tensor([1442,  165,    0, 9020,    0,  112, 6062, 1750]), tensor([119, 183,   0, 119,   0, 182, 119, 170]), tensor([11205,  2271,     0,  2098,     0, 21718,   160,  1862]), tensor([23830,  1766,     0,  1103,     0, 24186,  8914,  1177]), tensor([ 119, 6941,    0, 3271,    0, 1916, 1182, 1976]), tensor([ 119, 1152,    0, 1104,    0, 1198, 1108,  119]), tensor([  119,  1125,     0,  4041,     0,  2269,  3123, 11336]), tensor([ 1409,   170,     0,  1115,     0,  1142,  1106, 20629]), tensor([ 146, 3538,    0, 1128,    0, 3189, 7543, 1111]), tensor([  112, 27629,     0,  1243,     0,   119,  1106,  1115]), tensor([ 182, 4515,    0,  170,    0,  157, 1105,  119]), tensor([  172,  1548,     0,  1376,     0, 23377,  4344,  2038]), tensor([ 1611,  1358,     0,  4462,     0, 14918,  1108,  1106]), tensor([3970, 1134,    0, 1146,    0,  106, 2012, 1267]), tensor([ 170, 1108,    0, 1106,    0,  106,  119, 1106]), tensor([19359,  1897,     0,  1301,     0,   106,   165,  1800]), tensor([1114, 1363,    0, 1106,    0,  102,  183, 6573]), tensor([ 176,  102,    0,  117,    0,    0,  165, 1216]), tensor([7728,    0,    0, 1176,    0,    0,  183, 1601]), tensor([11597,     0,     0,  1234,     0,     0,  2064,  2209]), tensor([ 117,    0,    0, 1215,    0,    0, 3556, 1106]), tensor([1134,    0,    0, 1106,    0,    0,  131, 1147]), tensor([ 146,    0,    0, 1202,    0,    0, 1284, 5793]), tensor([1579,    0,    0, 1171,    0,    0, 1486,  119]), tensor([ 1821,     0,     0,  1107,     0,     0, 10366,   165]), tensor([ 117,    0,    0, 1103,    0,    0, 1104,  183]), tensor([ 113,    0,    0, 1285,    0,    0, 6363, 1942]), tensor([ 1128,     0,     0,   119,     0,     0,  1107, 27516]), tensor([1202,    0,    0,  146,    0,    0, 1142, 1169]), tensor([1315,    0,    0, 1108,    0,    0, 3415, 1178]), tensor([ 119,    0,    0, 6918,    0,    0,  119, 1129]), tensor([5890,    0,    0, 1536,    0,    0,  119,  170]), tensor([1122,    0,    0, 1106,    0,    0,  119, 1363]), tensor([ 114,    0,    0, 1267,    0,    0,  146, 1645]), tensor([15688,     0,     0,   170,     0,     0,  1221,   119]), tensor([ 7738,     0,     0, 15660,     0,     0,  1234,   165]), tensor([ 117,    0,    0, 2099,    0,    0, 1567,  183]), tensor([26704,     0,     0,  1104,     0,     0,  1147,  1942]), tensor([  117,     0,     0,  1103,     0,     0, 23463,  4638]), tensor([23982,     0,     0,   151,     0,     0,   117,  1269]), tensor([1105,    0,    0, 3818,    0,    0, 1133, 5039]), tensor([1653,    0,    0, 1665,    0,    0, 3525, 4557]), tensor([14313,     0,     0, 27733,     0,     0, 23463,  1112]), tensor([ 113,    0,    0, 1303,    0,    0, 1107, 1103]), tensor([ 141,    0,    0, 1107,    0,    0,  170, 1148]), tensor([2591,    0,    0, 1356,    0,    0, 3415, 1159]), tensor([20427,     0,     0,   117,     0,     0,  1443,  1213]), tensor([ 114,    0,    0, 1134,    0,    0, 4778,  119]), tensor([ 1173,     0,     0,  5544,     0,     0, 10335,  3615]), tensor([14812,     0,     0,  1110,     0,     0,  3375,  9918]), tensor([16442,     0,     0,  2426,     0,     0,  1110,  2897]), tensor([1186,    0,    0, 6547,    0,    0, 1198,  119]), tensor([1110,    0,    0, 1106,    0,    0, 4107, 1337]), tensor([2226,    0,    0, 3250,    0,    0, 1111, 1116]), tensor([ 1104,     0,     0, 10773,     0,     0, 22593,   170]), tensor([5953,    0,    0, 1133,    0,    0, 4490, 1974]), tensor([6665,    0,    0, 1103,    0,    0, 2645, 1104]), tensor([1107,    0,    0, 4041,    0,    0,  117, 5298]), tensor([1139,    0,    0, 1307,    0,    0, 2108,  119]), tensor([1520,    0,    0,  170,    0,    0, 1290, 1249]), tensor([ 119,    0,    0, 3321,    0,    0, 1211, 1163]), tensor([10672,     0,     0,  1648,     0,     0,  1234,  1107]), tensor([7688,    0,    0, 1145,    0,    0, 1519, 1139]), tensor([4044,    0,    0,  119,    0,    0, 1147, 1148]), tensor([ 1105,     0,     0,  5268,     0,     0, 23463,  1231]), tensor([ 1554,     0,     0,  1121,     0,     0,  1113, 11083]), tensor([1104,    0,    0, 1103,    0,    0, 1103, 1663]), tensor([1912,    0,    0, 1839,    0,    0, 1908, 2246]), tensor([19233,     0,     0,  1106,     0,     0,   119,   117]), tensor([ 1174,     0,     0,  1103,     0,     0, 18101,  1114]), tensor([2546,    0,    0, 7570,    0,    0,  117, 3615]), tensor([  119,     0,     0,  1108,     0,     0,  1195, 17180]), tensor([ 1109,     0,     0, 14820,     0,     0,  1238,   146]), tensor([5030,    0,    0, 1105,    0,    0,  112, 1156]), tensor([1974,    0,    0, 1122,    0,    0,  189, 2185]), tensor([1110,    0,    0, 1541,    0,    0, 1138, 1106]), tensor([7688,    0,    0, 1108,    0,    0, 1251, 1267]), tensor([2846,    0,    0,  170,    0,    0, 2645, 1167]), tensor([1106,    0,    0, 9214,    0,    0, 1114, 2783]), tensor([ 1243,     0,     0,  3440,     0,     0, 22593,  1105]), tensor([ 1107,     0,     0,   119,     0,     0, 14517,   170]), tensor([1105,    0,    0,  165,    0,    0,  119, 2113]), tensor([1149,    0,    0,  183,    0,    0, 1284, 1167]), tensor([ 1104,     0,     0,   165,     0,     0,   141, 10405]), tensor([1463,    0,    0,  183,    0,    0, 9949, 1114]), tensor([ 119,    0,    0, 1942,    0,    0, 1138, 4161]), tensor([ 4062,     0,     0, 12807,     0,     0,   170,  1106]), tensor([3404,    0,    0, 1110,    0,    0, 2463, 1103]), tensor([1120,    0,    0,  170,    0,    0, 1114, 5039]), tensor([5953,    0,    0, 1295,    0,    0, 1103, 5298]), tensor([1110,    0,    0, 1104,    0,    0, 1480, 9940]), tensor([ 170,    0,    0, 6668,    0,    0, 2546,  117]), tensor([8839,    0,    0, 1111,    0,    0,  117, 1173]), tensor([ 119,    0,    0, 1128,    0,    0, 1463, 1254]), tensor([2750,    0,    0, 1106,    0,    0,  119, 1150]), tensor([6920,    0,    0, 1138,    0,    0, 1109, 1156]), tensor([ 2033,     0,     0,   170,     0,     0,  9477, 19073]), tensor([5342,    0,    0, 3613,    0,    0, 1108, 1164]), tensor([1481,    0,    0, 5580,    0,    0, 3505,  170]), tensor([1800,    0,    0, 7136,    0,    0, 1536, 4557]), tensor([1774,    0,    0, 1219,    0,    0,  117,  192]), tensor([1106,    0,    0, 1103,    0,    0, 1133,  120]), tensor([ 2195,     0,     0, 14235,     0,     0,  1103,  1120]), tensor([1506,    0,    0,  117,    0,    0, 1248, 1655]), tensor([3404,    0,    0, 1133,    0,    0, 5141, 1969]), tensor([1120,    0,    0, 1128,    0,    0,  113, 8315]), tensor([ 1367,     0,     0,  1138,     0,     0,  1150, 23147]), tensor([9952,    0,    0, 1106,    0,    0, 1225, 1113]), tensor([ 1113,     0,     0,  1129,     0,     0,  1103, 12999]), tensor([ 170,    0,    0, 3613,    0,    0, 9374,  136]), tensor([18730,     0,     0,  1149,     0,     0,   117,  1337]), tensor([ 119,    0,    0, 1240,    0,    0,  146, 1116]), tensor([1135,    0,    0, 1946,    0,    0, 6699,  170]), tensor([ 112,    0,    0, 1272,    0,    0,  114, 1842]), tensor([ 188,    0,    0, 1122,    0,    0, 1144, 8268]), tensor([3513,    0,    0, 3370,    0,    0,  170,  119]), tensor([  119,     0,     0,  1304,     0,     0, 12342,   165]), tensor([ 1188,     0,     0,  5116,     0,     0, 20595,   183]), tensor([1282,    0,    0, 2698,    0,    0, 2346, 2346]), tensor([ 1156,     0,     0,   119,     0,     0, 13329,  2149]), tensor([ 5958,     0,     0,   165,     0,     0,  7533, 18343]), tensor([5257,    0,    0,  183,    0,    0, 2463, 6501]), tensor([1121,    0,    0,  165,    0,    0,  119, 1108]), tensor([ 1330,     0,     0,   183,     0,     0,  1153, 15496]), tensor([6300,    0,    0, 1942,    0,    0, 1108, 1164]), tensor([ 120,    0,    0, 5345,    0,    0, 1304, 1184]), tensor([ 3448,     0,     0,  6248,     0,     0, 14708,  1131]), tensor([1137,    0,    0, 1169,    0,    0, 1106, 1108]), tensor([ 170,    0,    0, 1129,    0,    0, 1139, 2688]), tensor([1831,    0,    0, 5865,    0,    0, 1922, 1134]), tensor([4568,    0,    0,  117,    0,    0, 6124, 1107]), tensor([ 119,    0,    0, 1133,    0,    0,  117, 4565]), tensor([3446,    0,    0, 1122,    0,    0, 1150,  112]), tensor([ 112,    0,    0, 1541,    0,    0, 2144,  188]), tensor([  188,     0,     0, 19119,     0,     0,   112,  2898]), tensor([4717,    0,    0, 1199,    0,    0,  189, 8315]), tensor([ 119,    0,    0, 1104,    0,    0, 1579, 5298]), tensor([ 119,    0,    0, 1103,    0,    0, 3368, 1661]), tensor([ 119,    0,    0, 1618,    0,    0, 1146, 1110]), tensor([ 119,    0,    0, 3068,    0,    0, 6099,  170]), tensor([ 165,    0,    0, 2196,    0,    0, 1483, 1992]), tensor([ 183,    0,    0, 1177,    0,    0, 1165, 4882]), tensor([ 165,    0,    0, 1122,    0,    0, 1122,  119]), tensor([ 183,    0,    0, 1110,    0,    0,  112, 1212]), tensor([3663,    0,    0, 3869,    0,    0,  188,  170]), tensor([6094,    0,    0, 1122,    0,    0, 1136, 1330]), tensor([1169,    0,    0, 1105,    0,    0, 4606, 3805]), tensor([ 112,    0,    0, 1122,    0,    0, 2626,  117]), tensor([ 189,    0,    0, 1541,    0,    0, 1106, 1142]), tensor([1541,    0,    0, 2228,    0,    0, 1123, 1159]), tensor([5854,    0,    0, 1111,    0,    0,  119, 1213]), tensor([ 170,    0,    0,  170,    0,    0, 1284, 1103]), tensor([6166,    0,    0, 3505,    0,    0, 1145, 2094]), tensor([1120,    0,    0, 3440,    0,    0, 1767,  146]), tensor([12591,     0,     0,  1149,     0,     0,  1142,  2802]), tensor([ 5953,     0,     0,   119,     0,     0, 17178,  1189]), tensor([1165,    0,    0,  102,    0,    0, 1590, 1122]), tensor([1128,    0,    0,    0,    0,    0, 1587, 1149]), tensor([1169,    0,    0,    0,    0,    0, 1412, 1104]), tensor([1138,    0,    0,    0,    0,    0, 8480, 1103]), tensor([13128,     0,     0,     0,     0,     0,  1395,  3119]), tensor([1137,    0,    0,    0,    0,    0, 1115, 1897]), tensor([ 170,    0,    0,    0,    0,    0,  165, 1976]), tensor([19359,     0,     0,     0,     0,     0,   107,   119]), tensor([  117,     0,     0,     0,     0,     0, 19141,  2066]), tensor([1396,    0,    0,    0,    0,    0,  141,  170]), tensor([9705,    0,    0,    0,    0,    0, 2346, 1143]), tensor([ 1905,     0,     0,     0,     0,     0, 24819, 17903]), tensor([ 117,    0,    0,    0,    0,    0, 1942, 5970]), tensor([15688,     0,     0,     0,     0,     0,   157,  2983]), tensor([ 7738,     0,     0,     0,     0,     0, 21678,  1179]), tensor([ 1105,     0,     0,     0,     0,     0,  2162, 19359]), tensor([  170,     0,     0,     0,     0,     0, 22157,   117]), tensor([ 3026,     0,     0,     0,     0,     0, 16972,  1133]), tensor([ 1104,     0,     0,     0,     0,     0, 25075,  3505]), tensor([ 170,    0,    0,    0,    0,    0, 1942,  119]), tensor([ 4592,     0,     0,     0,     0,     0, 19141,   165]), tensor([ 1111,     0,     0,     0,     0,     0, 23096,   183]), tensor([1223,    0,    0,    0,    0,    0, 3663, 1592]), tensor([  109,     0,     0,     0,     0,     0, 24162,  2339]), tensor([ 1275,     0,     0,     0,     0,     0, 15740,  1163]), tensor([1105,    0,    0,    0,    0,    0,  119,  117]), tensor([ 1129,     0,     0,     0,     0,     0, 19141,  1632]), tensor([1171,    0,    0,    0,    0,    0,  157, 1106]), tensor([ 1149,     0,     0,     0,     0,     0, 21678,  1267]), tensor([1103,    0,    0,    0,    0,    0, 2162, 1330]), tensor([1442,    0,    0,    0,    0,    0, 7462, 8315]), tensor([1105,    0,    0,    0,    0,    0,  143, 5298]), tensor([ 2917,     0,     0,     0,     0,     0, 21564,  1711]), tensor([ 1171,     0,     0,     0,     0,     0, 15681,  2866]), tensor([ 1106,     0,     0,     0,     0,     0, 18581,  1103]), tensor([1103,    0,    0,    0,    0,    0, 1708, 1526]), tensor([1701,    0,    0,    0,    0,    0, 2428,  119]), tensor([ 1137,     0,     0,     0,     0,     0, 16716,  8835]), tensor([ 2309,     0,     0,     0,     0,     0, 17730,  1106]), tensor([ 119,    0,    0,    0,    0,    0, 2036, 1138]), tensor([27652,     0,     0,     0,     0,     0,   157,  1128]), tensor([ 1106,     0,     0,     0,     0,     0, 21678,  1303]), tensor([ 1267,     0,     0,     0,     0,     0, 15928,   119]), tensor([ 1292,     0,     0,     0,     0,     0, 22157,   102]), tensor([ 3713,     0,     0,     0,     0,     0, 16972,     0]), tensor([ 1138,     0,     0,     0,     0,     0, 25075,     0]), tensor([1678,    0,    0,    0,    0,    0, 1942,    0]), tensor([1142,    0,    0,    0,    0,    0, 7462,    0]), tensor([1154,    0,    0,    0,    0,    0, 2107,    0]), tensor([3300,    0,    0,    0,    0,    0,  119,    0]), tensor([119,   0,   0,   0,   0,   0, 157,   0]), tensor([ 3473,     0,     0,     0,     0,     0, 11612,     0]), tensor([ 117,    0,    0,    0,    0,    0, 1942,    0]), tensor([ 1128,     0,     0,     0,     0,     0, 19432,     0]), tensor([1431,    0,    0,    0,    0,    0,  145,    0]), tensor([ 1221,     0,     0,     0,     0,     0, 17056,     0]), tensor([1115,    0,    0,    0,    0,    0, 9686,    0]), tensor([1103,    0,    0,    0,    0,    0,  160,    0]), tensor([ 109,    0,    0,    0,    0,    0, 9565,    0]), tensor([ 1275,     0,     0,     0,     0,     0, 25370,     0]), tensor([4733,    0,    0,    0,    0,    0,  119,    0]), tensor([2426,    0,    0,    0,    0,    0,  165,    0]), tensor([2502,    0,    0,    0,    0,    0,  107,    0]), tensor([1107,    0,    0,    0,    0,    0, 1398,    0]), tensor([1103,    0,    0,    0,    0,    0, 1107,    0]), tensor([4592,    0,    0,    0,    0,    0,  170,    0]), tensor([2853,    0,    0,    0,    0,    0, 4632,    0]), tensor([119,   0,   0,   0,   0,   0, 117,   0]), tensor([ 1789,     0,     0,     0,     0,     0, 19067,     0]), tensor([1336,    0,    0,    0,    0,    0, 1490,    0]), tensor([4752,    0,    0,    0,    0,    0,  119,    0]), tensor([1167,    0,    0,    0,    0,    0,  165,    0]), tensor([26704,     0,     0,     0,     0,     0,   183,     0]), tensor([1137,    0,    0,    0,    0,    0,  165,    0]), tensor([9323,    0,    0,    0,    0,    0,  183,    0]), tensor([ 117,    0,    0,    0,    0,    0, 2240,    0]), tensor([1134,    0,    0,    0,    0,    0, 6699,    0]), tensor([1169,    0,    0,    0,    0,    0, 1103,    0]), tensor([1129,    0,    0,    0,    0,    0, 6462,    0]), tensor([22726,     0,     0,     0,     0,     0,  1108,     0]), tensor([ 119,    0,    0,    0,    0,    0, 1198,    0]), tensor([  165,     0,     0,     0,     0,     0, 10899,     0]), tensor([183,   0,   0,   0,   0,   0, 119,   0]), tensor([ 165,    0,    0,    0,    0,    0, 6424,    0]), tensor([ 183,    0,    0,    0,    0,    0, 1609,    0]), tensor([1708,    0,    0,    0,    0,    0, 1113,    0]), tensor([1200,    0,    0,    0,    0,    0, 6092,    0]), tensor([14301,     0,     0,     0,     0,     0,  1105,     0]), tensor([1110,    0,    0,    0,    0,    0, 2302,    0]), tensor([1579,    0,    0,    0,    0,    0, 1113,    0]), tensor([ 3613,     0,     0,     0,     0,     0, 10928,     0]), tensor([1105,    0,    0,    0,    0,    0, 1610,    0]), tensor([4931,    0,    0,    0,    0,    0, 4832,    0]), tensor([119,   0,   0,   0,   0,   0, 117,   0]), tensor([1220,    0,    0,    0,    0,    0, 1133,    0]), tensor([1202,    0,    0,    0,    0,    0, 1122,    0]), tensor([ 170,    0,    0,    0,    0,    0, 1108,    0]), tensor([7310,    0,    0,    0,    0,    0, 1536,    0]), tensor([2261,    0,    0,    0,    0,    0, 1106,    0]), tensor([1104,    0,    0,    0,    0,    0, 1243,    0]), tensor([1143,    0,    0,    0,    0,    0, 1366,    0]), tensor([26271,     0,     0,     0,     0,     0,  1149,     0]), tensor([4404,    0,    0,    0,    0,    0, 1104,    0]), tensor([3791,    0,    0,    0,    0,    0, 1103,    0]), tensor([ 119,    0,    0,    0,    0,    0, 1442,    0]), tensor([25574,     0,     0,     0,     0,     0,  1107,     0]), tensor([1193,    0,    0,    0,    0,    0, 1103,    0]), tensor([1144,    0,    0,    0,    0,    0, 2106,    0]), tensor([1122,    0,    0,    0,    0,    0,  119,    0]), tensor([1435,    0,    0,    0,    0,    0, 1284,    0]), tensor([1106,    0,    0,    0,    0,    0, 3851,    0]), tensor([2789,    0,    0,    0,    0,    0, 1142,    0]), tensor([1115,    0,    0,    0,    0,    0, 3415,    0]), tensor([1139,    0,    0,    0,    0,    0,  117,    0]), tensor([1546,    0,    0,    0,    0,    0, 1133,    0]), tensor([1144,    0,    0,    0,    0,    0, 1547,    0]), tensor([1151,    0,    0,    0,    0,    0, 3644,    0]), tensor([12477,     0,     0,     0,     0,     0,  1142,     0]), tensor([1233,    0,    0,    0,    0,    0, 2440,    0]), tensor([ 118,    0,    0,    0,    0,    0, 2001,    0]), tensor([4653,    0,    0,    0,    0,    0,  154,    0]), tensor([  119,     0,     0,     0,     0,     0, 14846,     0]), tensor([18911,     0,     0,     0,     0,     0,  1777,     0]), tensor([1113,    0,    0,    0,    0,    0, 1272,    0]), tensor([1231,    0,    0,    0,    0,    0, 1104,    0]), tensor([18591,     0,     0,     0,     0,     0,  1115,     0]), tensor([1116,    0,    0,    0,    0,    0, 5141,    0]), tensor([1105,    0,    0,    0,    0,    0,  119,    0]), tensor([ 146,    0,    0,    0,    0,    0, 1258,    0]), tensor([1567,    0,    0,    0,    0,    0, 2005,    0]), tensor([1115,    0,    0,    0,    0,    0, 1104,    0]), tensor([1152,    0,    0,    0,    0,    0, 3759,    0]), tensor([1579,    0,    0,    0,    0,    0,  117,    0]), tensor([2906,    0,    0,    0,    0,    0, 1195,    0]), tensor([ 170,    0,    0,    0,    0,    0, 1328,    0]), tensor([1106,    0,    0,    0,    0,    0, 8402,    0]), tensor([ 118,    0,    0,    0,    0,    0, 1105,    0]), tensor([1301,    0,    0,    0,    0,    0, 1136,    0]), tensor([24802,     0,     0,     0,     0,     0, 14708,     0]), tensor([  119,     0,     0,     0,     0,     0, 26635,     0]), tensor([ 165,    0,    0,    0,    0,    0, 1121,    0]), tensor([107,   0,   0,   0,   0,   0, 170,   0]), tensor([2009,    0,    0,    0,    0,    0, 2546,    0]), tensor([ 117,    0,    0,    0,    0,    0, 1420,    0]), tensor([4208,    0,    0,    0,    0,    0, 1115,    0]), tensor([ 106,    0,    0,    0,    0,    0, 9521,    0]), tensor([ 146,    0,    0,    0,    0,    0, 1103,    0]), tensor([1156,    0,    0,    0,    0,    0, 6363,    0]), tensor([1567,    0,    0,    0,    0,    0, 1115,    0]), tensor([ 170,    0,    0,    0,    0,    0, 2498,    0]), tensor([10211,     0,     0,     0,     0,     0, 22593,     0]), tensor([ 1884,     0,     0,     0,     0,     0, 14517,     0]), tensor([2391,    0,    0,    0,    0,    0, 1154,    0]), tensor([1106,    0,    0,    0,    0,    0, 1103,    0]), tensor([1301,    0,    0,    0,    0,    0, 4045,    0]), tensor([106,   0,   0,   0,   0,   0, 119,   0]), tensor([1731,    0,    0,    0,    0,    0,  119,    0]), tensor([17873,     0,     0,     0,     0,     0,   119,     0]), tensor([106,   0,   0,   0,   0,   0, 119,   0]), tensor([165,   0,   0,   0,   0,   0, 165,   0]), tensor([107,   0,   0,   0,   0,   0, 183,   0]), tensor([12004,     0,     0,     0,     0,     0,   165,     0]), tensor([1277,    0,    0,    0,    0,    0,  183,    0]), tensor([1579,    0,    0,    0,    0,    0, 1592,    0]), tensor([1139,    0,    0,    0,    0,    0, 3447,    0]), tensor([1354,    0,    0,    0,    0,    0, 1186,    0]), tensor([1965,    0,    0,    0,    0,    0, 1104,    0]), tensor([ 119,    0,    0,    0,    0,    0, 3805,    0]), tensor([165,   0,   0,   0,   0,   0, 131,   0]), tensor([ 183,    0,    0,    0,    0,    0, 1192,    0]), tensor([ 165,    0,    0,    0,    0,    0, 1169,    0]), tensor([ 183,    0,    0,    0,    0,    0, 4837,    0]), tensor([1942,    0,    0,    0,    0,    0,  170,    0]), tensor([27516,     0,     0,     0,     0,     0,  1395,     0]), tensor([1282,    0,    0,    0,    0,    0, 1114,    0]), tensor([1145,    0,    0,    0,    0,    0,  170,    0]), tensor([1674,    0,    0,    0,    0,    0, 3621,    0]), tensor([1554,    0,    0,    0,    0,    0,  117,    0]), tensor([4014,    0,    0,    0,    0,    0, 1133,    0]), tensor([6665,    0,    0,    0,    0,    0, 1128,    0]), tensor([1105,    0,    0,    0,    0,    0, 1538,    0]), tensor([ 1144,     0,     0,     0,     0,     0, 18589,     0]), tensor([28117,     0,     0,     0,     0,     0, 23161,     0]), tensor([5933,    0,    0,    0,    0,    0, 1519,    0]), tensor([ 119,    0,    0,    0,    0,    0, 1172,    0]), tensor([8853,    0,    0,    0,    0,    0, 1508,    0]), tensor([1104,    0,    0,    0,    0,    0,  170,    0]), tensor([1134,    0,    0,    0,    0,    0, 2080,    0]), tensor([ 146,    0,    0,    0,    0,    0, 1113,    0]), tensor([1138,    0,    0,    0,    0,    0, 1240,    0]), tensor([1793,    0,    0,    0,    0,    0, 3621,    0]), tensor([1106,    0,    0,    0,    0,    0, 1111,    0]), tensor([2236,    0,    0,    0,    0,    0, 1103,    0]), tensor([ 117,    0,    0,    0,    0,    0, 1554,    0]), tensor([1133,    0,    0,    0,    0,    0, 1395,    0]), tensor([1156,    0,    0,    0,    0,    0, 2971,    0]), tensor([11786,     0,     0,     0,     0,     0,  1235,     0]), tensor([ 184,    0,    0,    0,    0,    0, 4031,    0]), tensor([1830,    0,    0,    0,    0,    0, 3554,    0]), tensor([2646,    0,    0,    0,    0,    0,  119,    0]), tensor([2176,    0,    0,    0,    0,    0, 1192,    0]), tensor([1191,    0,    0,    0,    0,    0, 1169,    0]), tensor([1103,    0,    0,    0,    0,    0, 2653,    0]), tensor([5146,    0,    0,    0,    0,    0, 5948,    0]), tensor([1108,    0,    0,    0,    0,    0, 1120,    0]), tensor([2756,    0,    0,    0,    0,    0, 4031,    0]), tensor([ 119,    0,    0,    0,    0,    0, 3554,    0]), tensor([165,   0,   0,   0,   0,   0, 119,   0]), tensor([ 183,    0,    0,    0,    0,    0, 1188,    0]), tensor([ 165,    0,    0,    0,    0,    0, 1445,    0]), tensor([183,   0,   0,   0,   0,   0, 112,   0]), tensor([1942,    0,    0,    0,    0,    0,  189,    0]), tensor([3822,    0,    0,    0,    0,    0, 3716,    0]), tensor([4616,    0,    0,    0,    0,    0, 1106,    0]), tensor([1111,    0,    0,    0,    0,    0, 1366,    0]), tensor([1103,    0,    0,    0,    0,    0, 1235,    0]), tensor([3613,    0,    0,    0,    0,    0, 1195,    0]), tensor([1105,    0,    0,    0,    0,    0, 1127,    0]), tensor([15021,     0,     0,     0,     0,     0,  1120,     0]), tensor([5953,    0,    0,    0,    0,    0, 1103,    0]), tensor([ 120,    0,    0,    0,    0,    0, 4073,    0]), tensor([1555,    0,    0,    0,    0,    0,  119,    0]), tensor([117,   0,   0,   0,   0,   0, 102,   0]), tensor([14812,     0,     0,     0,     0,     0,     0,     0]), tensor([16442,     0,     0,     0,     0,     0,     0,     0]), tensor([1186,    0,    0,    0,    0,    0,    0,    0]), tensor([106,   0,   0,   0,   0,   0,   0,   0]), tensor([102,   0,   0,   0,   0,   0,   0,   0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0])], 'token_type_ids': [tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0])]}\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-7e4f51082525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         )\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"]}]},{"cell_type":"code","source":["blub = {k: v for k, v in batch.items()}"],"metadata":{"id":"Bmca6l-PYgjz","executionInfo":{"status":"ok","timestamp":1657126853385,"user_tz":-120,"elapsed":217,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["blub"],"metadata":{"id":"qPe5XeN9dRhg","executionInfo":{"status":"ok","timestamp":1657126855707,"user_tz":-120,"elapsed":8,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"4881a1b9-9773-4900-ac43-0089655061ca","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [tensor([101, 101, 101, 101, 101, 101, 101, 101]),\n","  tensor([14812, 19383, 12008,  1188,   146,  3930,  1284,  6682]),\n","  tensor([16442,  1303, 27788,  1110,  1274, 13991,  3523,  3537]),\n","  tensor([1186, 1111, 6434,  170,  112,  117, 1303, 1171]),\n","  tensor([1110, 1275, 2094, 2712,  189, 1147, 1103, 1118]),\n","  tensor([ 1240,  1552,   102,  4041,  2385,  2094,  1480, 11637]),\n","  tensor([1576, 1105,    0, 1114, 1243, 1110, 1196, 6737]),\n","  tensor([  118,  6218,     0,   170,  1142,  6976,  1139, 19569]),\n","  tensor([ 1104,  1107,     0, 10144,  1282,   117,  6124,  2737]),\n","  tensor([ 118,  170,    0, 2525, 1137, 1133,  112, 6077]),\n","  tensor([ 1103, 14255,     0,  1524,  1725,  1147,   188,  1114]),\n","  tensor([ 118, 2572,    0, 1134, 3141, 1106, 3043, 1139]),\n","  tensor([6159,  165,    0, 1110, 1116, 3740, 1105, 6642]),\n","  tensor([1983,  183,    0, 1632, 1567, 5878, 1238, 6193]),\n","  tensor([1457, 2137,    0, 1111, 1122, 1116,  112, 1121]),\n","  tensor([23783,  2047,     0,  2903,   117,  1132,   189,   139]),\n","  tensor([ 3255,  3970,     0,  1103,  1133,  1103,  1541, 11899]),\n","  tensor([  119,  1213,     0,  1362,  1122,  1436,  1221, 10145]),\n","  tensor([14380,  1105,     0,  1301,  1110,  1107,  1184,   119]),\n","  tensor([2930, 1276,    0, 4417, 1304,  153, 1106,  111]),\n","  tensor([1114, 1142,    0, 1229, 1363, 3048, 5363,  170]),\n","  tensor([13628,  1282,     0,  1515,   131,  3190,   119,  1374]),\n","  tensor([1116,  165,    0,  170,  114,  117, 1284, 1104]),\n","  tensor([ 188,  183,    0, 3538,  102, 1313, 1127, 1412]),\n","  tensor([ 1979,  1592,     0,   119,     0,  1104, 10287, 16195]),\n","  tensor([1158, 1566,    0,  165,    0, 1103, 1193, 6356]),\n","  tensor([23982,  1303,     0,   183,     0,  1436,  3753,  4427]),\n","  tensor([21315,   123,     0,   165,     0,  4112,  1115,  1229]),\n","  tensor([ 1213,  1775,     0,   183,     0,  2094,  1122, 11030]),\n","  tensor([ 1103,   113,     0,  2240,     0,  1107,  1108, 17872]),\n","  tensor([17022, 14557,     0,  1138,     0,  1103,   170,  1113]),\n","  tensor([ 7659, 11273,     0, 15263,     0,  1646,  2785,   170]),\n","  tensor([1877,  116,    0, 5628,    0,  119, 1363, 1285]),\n","  tensor([ 1176, 20333,     0,  1104,     0,   119,  1671,  1228]),\n","  tensor([1122,  114,    0, 1909,    0,  119, 3415,  119]),\n","  tensor([ 112,  165,    0, 1106,    0, 1115,  106,  165]),\n","  tensor([ 188,  183,    0, 1142,    0, 1110,  146,  183]),\n","  tensor([ 170, 2271,    0, 4041,    0, 2157,  112, 2271]),\n","  tensor([ 5953, 13465,     0,  1106,     0,   170,  1325, 11836]),\n","  tensor([4974, 1108,    0, 1267,    0, 1974, 2190, 1204]),\n","  tensor([3974, 4489,    0, 1103,    0,  117, 1103,  146]),\n","  tensor([ 1437,   116,     0, 10921,     0,   146,  1363,  1538]),\n","  tensor([  119, 22515,     0,  1290,     0,  1221,  1105,  1474]),\n","  tensor([10672, 13913,     0,   146,     0,   117,  2213,  1139]),\n","  tensor([  170,   165,     0,  1108,     0,  1133, 10380,  1862]),\n","  tensor([ 185,  183,    0, 1304,    0, 4268,  119, 3868]),\n","  tensor([5765, 1708,    0, 1685,    0, 4031,  165, 1108]),\n","  tensor([16426, 13148,     0,   119,     0,  1172,   183, 13241]),\n","  tensor([1104, 1182,    0,  146,    0, 1149,  165, 1118]),\n","  tensor([12375,  1108,     0,  1897,     0,  1111,   183,  1126]),\n","  tensor([ 1105,  1632,     0, 21389,     0,  3739,  2349,  5670]),\n","  tensor([21102,  1111,     0,  2676,     0,   119, 13465,  2593]),\n","  tensor([1116, 1103,    0, 1113,    0,  146,  131, 1121]),\n","  tensor([1280, 3945,    0, 1139,    0,  112, 1109, 1106]),\n","  tensor([1213,  165,    0, 5612,    0,  182, 8675, 1139]),\n","  tensor([1103,  183,    0, 5913,    0, 1280, 1127, 2198]),\n","  tensor([ 1372,  1708,     0, 26979,     0,  1171,  4044, 15821]),\n","  tensor([ 119, 8167,    0, 1158,    0, 1106,  117, 1233]),\n","  tensor([ 165, 4060,    0, 1113,    0,  153, 1103, 1643]),\n","  tensor([ 183, 1643,    0, 1103,    0, 3048, 1395, 3189]),\n","  tensor([  165, 10899,     0,  4377,     0,  3190,  1108,  1121]),\n","  tensor([  183,  1133,     0,  1219,     0,  1770,  4044, 11637]),\n","  tensor([1942, 1164,    0,  170,    0, 1111,  117, 6737]),\n","  tensor([27516,  1103,     0,  2099,     0,  1103,  1103, 19569]),\n","  tensor([1282, 1269,    0, 1104,    0, 1148, 1447, 2737]),\n","  tensor([ 1110,  1112,     0, 24139,     0,  1159,  1108,  6077]),\n","  tensor([1632, 1168,    0,  119,    0, 1290, 2633,  112]),\n","  tensor([1111,  171,    0, 7066,    0, 2232,  117,  188]),\n","  tensor([5953, 9435,    0, 1324,    0, 1283, 1103, 3172]),\n","  tensor([  119,  6248,     0,  5628,     0,   117, 23134,  5525]),\n","  tensor([ 109,  165,    0,  119,    0, 1105, 1127,  119]),\n","  tensor([ 130,  183,    0,  165,    0, 2938, 1363,  146]),\n","  tensor([1105, 1708,    0,  183,    0,  112, 1111, 1238]),\n","  tensor([1476, 1279,    0,  165,    0,  188, 1103, 1204]),\n","  tensor([ 1904, 16470,     0,   183,     0,  1209,  3945,  5363]),\n","  tensor([1105, 7318,    0, 2064,    0, 1129, 1553, 1251]),\n","  tensor([1128, 1127,    0, 3818,    0, 1139, 1105, 1231]),\n","  tensor([ 112, 4941,    0, 1142,    0, 1148, 1103, 5674]),\n","  tensor([ 1231,  1162,     0,  4041,     0,  1831,  9884, 19054]),\n","  tensor([1149, 1105,    0, 1541,    0,  119, 1127,  117]),\n","  tensor([1103, 1632,    0, 1110,    0,  146, 6751, 1277]),\n","  tensor([1442,  165,    0, 9020,    0,  112, 6062, 1750]),\n","  tensor([119, 183,   0, 119,   0, 182, 119, 170]),\n","  tensor([11205,  2271,     0,  2098,     0, 21718,   160,  1862]),\n","  tensor([23830,  1766,     0,  1103,     0, 24186,  8914,  1177]),\n","  tensor([ 119, 6941,    0, 3271,    0, 1916, 1182, 1976]),\n","  tensor([ 119, 1152,    0, 1104,    0, 1198, 1108,  119]),\n","  tensor([  119,  1125,     0,  4041,     0,  2269,  3123, 11336]),\n","  tensor([ 1409,   170,     0,  1115,     0,  1142,  1106, 20629]),\n","  tensor([ 146, 3538,    0, 1128,    0, 3189, 7543, 1111]),\n","  tensor([  112, 27629,     0,  1243,     0,   119,  1106,  1115]),\n","  tensor([ 182, 4515,    0,  170,    0,  157, 1105,  119]),\n","  tensor([  172,  1548,     0,  1376,     0, 23377,  4344,  2038]),\n","  tensor([ 1611,  1358,     0,  4462,     0, 14918,  1108,  1106]),\n","  tensor([3970, 1134,    0, 1146,    0,  106, 2012, 1267]),\n","  tensor([ 170, 1108,    0, 1106,    0,  106,  119, 1106]),\n","  tensor([19359,  1897,     0,  1301,     0,   106,   165,  1800]),\n","  tensor([1114, 1363,    0, 1106,    0,  102,  183, 6573]),\n","  tensor([ 176,  102,    0,  117,    0,    0,  165, 1216]),\n","  tensor([7728,    0,    0, 1176,    0,    0,  183, 1601]),\n","  tensor([11597,     0,     0,  1234,     0,     0,  2064,  2209]),\n","  tensor([ 117,    0,    0, 1215,    0,    0, 3556, 1106]),\n","  tensor([1134,    0,    0, 1106,    0,    0,  131, 1147]),\n","  tensor([ 146,    0,    0, 1202,    0,    0, 1284, 5793]),\n","  tensor([1579,    0,    0, 1171,    0,    0, 1486,  119]),\n","  tensor([ 1821,     0,     0,  1107,     0,     0, 10366,   165]),\n","  tensor([ 117,    0,    0, 1103,    0,    0, 1104,  183]),\n","  tensor([ 113,    0,    0, 1285,    0,    0, 6363, 1942]),\n","  tensor([ 1128,     0,     0,   119,     0,     0,  1107, 27516]),\n","  tensor([1202,    0,    0,  146,    0,    0, 1142, 1169]),\n","  tensor([1315,    0,    0, 1108,    0,    0, 3415, 1178]),\n","  tensor([ 119,    0,    0, 6918,    0,    0,  119, 1129]),\n","  tensor([5890,    0,    0, 1536,    0,    0,  119,  170]),\n","  tensor([1122,    0,    0, 1106,    0,    0,  119, 1363]),\n","  tensor([ 114,    0,    0, 1267,    0,    0,  146, 1645]),\n","  tensor([15688,     0,     0,   170,     0,     0,  1221,   119]),\n","  tensor([ 7738,     0,     0, 15660,     0,     0,  1234,   165]),\n","  tensor([ 117,    0,    0, 2099,    0,    0, 1567,  183]),\n","  tensor([26704,     0,     0,  1104,     0,     0,  1147,  1942]),\n","  tensor([  117,     0,     0,  1103,     0,     0, 23463,  4638]),\n","  tensor([23982,     0,     0,   151,     0,     0,   117,  1269]),\n","  tensor([1105,    0,    0, 3818,    0,    0, 1133, 5039]),\n","  tensor([1653,    0,    0, 1665,    0,    0, 3525, 4557]),\n","  tensor([14313,     0,     0, 27733,     0,     0, 23463,  1112]),\n","  tensor([ 113,    0,    0, 1303,    0,    0, 1107, 1103]),\n","  tensor([ 141,    0,    0, 1107,    0,    0,  170, 1148]),\n","  tensor([2591,    0,    0, 1356,    0,    0, 3415, 1159]),\n","  tensor([20427,     0,     0,   117,     0,     0,  1443,  1213]),\n","  tensor([ 114,    0,    0, 1134,    0,    0, 4778,  119]),\n","  tensor([ 1173,     0,     0,  5544,     0,     0, 10335,  3615]),\n","  tensor([14812,     0,     0,  1110,     0,     0,  3375,  9918]),\n","  tensor([16442,     0,     0,  2426,     0,     0,  1110,  2897]),\n","  tensor([1186,    0,    0, 6547,    0,    0, 1198,  119]),\n","  tensor([1110,    0,    0, 1106,    0,    0, 4107, 1337]),\n","  tensor([2226,    0,    0, 3250,    0,    0, 1111, 1116]),\n","  tensor([ 1104,     0,     0, 10773,     0,     0, 22593,   170]),\n","  tensor([5953,    0,    0, 1133,    0,    0, 4490, 1974]),\n","  tensor([6665,    0,    0, 1103,    0,    0, 2645, 1104]),\n","  tensor([1107,    0,    0, 4041,    0,    0,  117, 5298]),\n","  tensor([1139,    0,    0, 1307,    0,    0, 2108,  119]),\n","  tensor([1520,    0,    0,  170,    0,    0, 1290, 1249]),\n","  tensor([ 119,    0,    0, 3321,    0,    0, 1211, 1163]),\n","  tensor([10672,     0,     0,  1648,     0,     0,  1234,  1107]),\n","  tensor([7688,    0,    0, 1145,    0,    0, 1519, 1139]),\n","  tensor([4044,    0,    0,  119,    0,    0, 1147, 1148]),\n","  tensor([ 1105,     0,     0,  5268,     0,     0, 23463,  1231]),\n","  tensor([ 1554,     0,     0,  1121,     0,     0,  1113, 11083]),\n","  tensor([1104,    0,    0, 1103,    0,    0, 1103, 1663]),\n","  tensor([1912,    0,    0, 1839,    0,    0, 1908, 2246]),\n","  tensor([19233,     0,     0,  1106,     0,     0,   119,   117]),\n","  tensor([ 1174,     0,     0,  1103,     0,     0, 18101,  1114]),\n","  tensor([2546,    0,    0, 7570,    0,    0,  117, 3615]),\n","  tensor([  119,     0,     0,  1108,     0,     0,  1195, 17180]),\n","  tensor([ 1109,     0,     0, 14820,     0,     0,  1238,   146]),\n","  tensor([5030,    0,    0, 1105,    0,    0,  112, 1156]),\n","  tensor([1974,    0,    0, 1122,    0,    0,  189, 2185]),\n","  tensor([1110,    0,    0, 1541,    0,    0, 1138, 1106]),\n","  tensor([7688,    0,    0, 1108,    0,    0, 1251, 1267]),\n","  tensor([2846,    0,    0,  170,    0,    0, 2645, 1167]),\n","  tensor([1106,    0,    0, 9214,    0,    0, 1114, 2783]),\n","  tensor([ 1243,     0,     0,  3440,     0,     0, 22593,  1105]),\n","  tensor([ 1107,     0,     0,   119,     0,     0, 14517,   170]),\n","  tensor([1105,    0,    0,  165,    0,    0,  119, 2113]),\n","  tensor([1149,    0,    0,  183,    0,    0, 1284, 1167]),\n","  tensor([ 1104,     0,     0,   165,     0,     0,   141, 10405]),\n","  tensor([1463,    0,    0,  183,    0,    0, 9949, 1114]),\n","  tensor([ 119,    0,    0, 1942,    0,    0, 1138, 4161]),\n","  tensor([ 4062,     0,     0, 12807,     0,     0,   170,  1106]),\n","  tensor([3404,    0,    0, 1110,    0,    0, 2463, 1103]),\n","  tensor([1120,    0,    0,  170,    0,    0, 1114, 5039]),\n","  tensor([5953,    0,    0, 1295,    0,    0, 1103, 5298]),\n","  tensor([1110,    0,    0, 1104,    0,    0, 1480, 9940]),\n","  tensor([ 170,    0,    0, 6668,    0,    0, 2546,  117]),\n","  tensor([8839,    0,    0, 1111,    0,    0,  117, 1173]),\n","  tensor([ 119,    0,    0, 1128,    0,    0, 1463, 1254]),\n","  tensor([2750,    0,    0, 1106,    0,    0,  119, 1150]),\n","  tensor([6920,    0,    0, 1138,    0,    0, 1109, 1156]),\n","  tensor([ 2033,     0,     0,   170,     0,     0,  9477, 19073]),\n","  tensor([5342,    0,    0, 3613,    0,    0, 1108, 1164]),\n","  tensor([1481,    0,    0, 5580,    0,    0, 3505,  170]),\n","  tensor([1800,    0,    0, 7136,    0,    0, 1536, 4557]),\n","  tensor([1774,    0,    0, 1219,    0,    0,  117,  192]),\n","  tensor([1106,    0,    0, 1103,    0,    0, 1133,  120]),\n","  tensor([ 2195,     0,     0, 14235,     0,     0,  1103,  1120]),\n","  tensor([1506,    0,    0,  117,    0,    0, 1248, 1655]),\n","  tensor([3404,    0,    0, 1133,    0,    0, 5141, 1969]),\n","  tensor([1120,    0,    0, 1128,    0,    0,  113, 8315]),\n","  tensor([ 1367,     0,     0,  1138,     0,     0,  1150, 23147]),\n","  tensor([9952,    0,    0, 1106,    0,    0, 1225, 1113]),\n","  tensor([ 1113,     0,     0,  1129,     0,     0,  1103, 12999]),\n","  tensor([ 170,    0,    0, 3613,    0,    0, 9374,  136]),\n","  tensor([18730,     0,     0,  1149,     0,     0,   117,  1337]),\n","  tensor([ 119,    0,    0, 1240,    0,    0,  146, 1116]),\n","  tensor([1135,    0,    0, 1946,    0,    0, 6699,  170]),\n","  tensor([ 112,    0,    0, 1272,    0,    0,  114, 1842]),\n","  tensor([ 188,    0,    0, 1122,    0,    0, 1144, 8268]),\n","  tensor([3513,    0,    0, 3370,    0,    0,  170,  119]),\n","  tensor([  119,     0,     0,  1304,     0,     0, 12342,   165]),\n","  tensor([ 1188,     0,     0,  5116,     0,     0, 20595,   183]),\n","  tensor([1282,    0,    0, 2698,    0,    0, 2346, 2346]),\n","  tensor([ 1156,     0,     0,   119,     0,     0, 13329,  2149]),\n","  tensor([ 5958,     0,     0,   165,     0,     0,  7533, 18343]),\n","  tensor([5257,    0,    0,  183,    0,    0, 2463, 6501]),\n","  tensor([1121,    0,    0,  165,    0,    0,  119, 1108]),\n","  tensor([ 1330,     0,     0,   183,     0,     0,  1153, 15496]),\n","  tensor([6300,    0,    0, 1942,    0,    0, 1108, 1164]),\n","  tensor([ 120,    0,    0, 5345,    0,    0, 1304, 1184]),\n","  tensor([ 3448,     0,     0,  6248,     0,     0, 14708,  1131]),\n","  tensor([1137,    0,    0, 1169,    0,    0, 1106, 1108]),\n","  tensor([ 170,    0,    0, 1129,    0,    0, 1139, 2688]),\n","  tensor([1831,    0,    0, 5865,    0,    0, 1922, 1134]),\n","  tensor([4568,    0,    0,  117,    0,    0, 6124, 1107]),\n","  tensor([ 119,    0,    0, 1133,    0,    0,  117, 4565]),\n","  tensor([3446,    0,    0, 1122,    0,    0, 1150,  112]),\n","  tensor([ 112,    0,    0, 1541,    0,    0, 2144,  188]),\n","  tensor([  188,     0,     0, 19119,     0,     0,   112,  2898]),\n","  tensor([4717,    0,    0, 1199,    0,    0,  189, 8315]),\n","  tensor([ 119,    0,    0, 1104,    0,    0, 1579, 5298]),\n","  tensor([ 119,    0,    0, 1103,    0,    0, 3368, 1661]),\n","  tensor([ 119,    0,    0, 1618,    0,    0, 1146, 1110]),\n","  tensor([ 119,    0,    0, 3068,    0,    0, 6099,  170]),\n","  tensor([ 165,    0,    0, 2196,    0,    0, 1483, 1992]),\n","  tensor([ 183,    0,    0, 1177,    0,    0, 1165, 4882]),\n","  tensor([ 165,    0,    0, 1122,    0,    0, 1122,  119]),\n","  tensor([ 183,    0,    0, 1110,    0,    0,  112, 1212]),\n","  tensor([3663,    0,    0, 3869,    0,    0,  188,  170]),\n","  tensor([6094,    0,    0, 1122,    0,    0, 1136, 1330]),\n","  tensor([1169,    0,    0, 1105,    0,    0, 4606, 3805]),\n","  tensor([ 112,    0,    0, 1122,    0,    0, 2626,  117]),\n","  tensor([ 189,    0,    0, 1541,    0,    0, 1106, 1142]),\n","  tensor([1541,    0,    0, 2228,    0,    0, 1123, 1159]),\n","  tensor([5854,    0,    0, 1111,    0,    0,  119, 1213]),\n","  tensor([ 170,    0,    0,  170,    0,    0, 1284, 1103]),\n","  tensor([6166,    0,    0, 3505,    0,    0, 1145, 2094]),\n","  tensor([1120,    0,    0, 3440,    0,    0, 1767,  146]),\n","  tensor([12591,     0,     0,  1149,     0,     0,  1142,  2802]),\n","  tensor([ 5953,     0,     0,   119,     0,     0, 17178,  1189]),\n","  tensor([1165,    0,    0,  102,    0,    0, 1590, 1122]),\n","  tensor([1128,    0,    0,    0,    0,    0, 1587, 1149]),\n","  tensor([1169,    0,    0,    0,    0,    0, 1412, 1104]),\n","  tensor([1138,    0,    0,    0,    0,    0, 8480, 1103]),\n","  tensor([13128,     0,     0,     0,     0,     0,  1395,  3119]),\n","  tensor([1137,    0,    0,    0,    0,    0, 1115, 1897]),\n","  tensor([ 170,    0,    0,    0,    0,    0,  165, 1976]),\n","  tensor([19359,     0,     0,     0,     0,     0,   107,   119]),\n","  tensor([  117,     0,     0,     0,     0,     0, 19141,  2066]),\n","  tensor([1396,    0,    0,    0,    0,    0,  141,  170]),\n","  tensor([9705,    0,    0,    0,    0,    0, 2346, 1143]),\n","  tensor([ 1905,     0,     0,     0,     0,     0, 24819, 17903]),\n","  tensor([ 117,    0,    0,    0,    0,    0, 1942, 5970]),\n","  tensor([15688,     0,     0,     0,     0,     0,   157,  2983]),\n","  tensor([ 7738,     0,     0,     0,     0,     0, 21678,  1179]),\n","  tensor([ 1105,     0,     0,     0,     0,     0,  2162, 19359]),\n","  tensor([  170,     0,     0,     0,     0,     0, 22157,   117]),\n","  tensor([ 3026,     0,     0,     0,     0,     0, 16972,  1133]),\n","  tensor([ 1104,     0,     0,     0,     0,     0, 25075,  3505]),\n","  tensor([ 170,    0,    0,    0,    0,    0, 1942,  119]),\n","  tensor([ 4592,     0,     0,     0,     0,     0, 19141,   165]),\n","  tensor([ 1111,     0,     0,     0,     0,     0, 23096,   183]),\n","  tensor([1223,    0,    0,    0,    0,    0, 3663, 1592]),\n","  tensor([  109,     0,     0,     0,     0,     0, 24162,  2339]),\n","  tensor([ 1275,     0,     0,     0,     0,     0, 15740,  1163]),\n","  tensor([1105,    0,    0,    0,    0,    0,  119,  117]),\n","  tensor([ 1129,     0,     0,     0,     0,     0, 19141,  1632]),\n","  tensor([1171,    0,    0,    0,    0,    0,  157, 1106]),\n","  tensor([ 1149,     0,     0,     0,     0,     0, 21678,  1267]),\n","  tensor([1103,    0,    0,    0,    0,    0, 2162, 1330]),\n","  tensor([1442,    0,    0,    0,    0,    0, 7462, 8315]),\n","  tensor([1105,    0,    0,    0,    0,    0,  143, 5298]),\n","  tensor([ 2917,     0,     0,     0,     0,     0, 21564,  1711]),\n","  tensor([ 1171,     0,     0,     0,     0,     0, 15681,  2866]),\n","  tensor([ 1106,     0,     0,     0,     0,     0, 18581,  1103]),\n","  tensor([1103,    0,    0,    0,    0,    0, 1708, 1526]),\n","  tensor([1701,    0,    0,    0,    0,    0, 2428,  119]),\n","  tensor([ 1137,     0,     0,     0,     0,     0, 16716,  8835]),\n","  tensor([ 2309,     0,     0,     0,     0,     0, 17730,  1106]),\n","  tensor([ 119,    0,    0,    0,    0,    0, 2036, 1138]),\n","  tensor([27652,     0,     0,     0,     0,     0,   157,  1128]),\n","  tensor([ 1106,     0,     0,     0,     0,     0, 21678,  1303]),\n","  tensor([ 1267,     0,     0,     0,     0,     0, 15928,   119]),\n","  tensor([ 1292,     0,     0,     0,     0,     0, 22157,   102]),\n","  tensor([ 3713,     0,     0,     0,     0,     0, 16972,     0]),\n","  tensor([ 1138,     0,     0,     0,     0,     0, 25075,     0]),\n","  tensor([1678,    0,    0,    0,    0,    0, 1942,    0]),\n","  tensor([1142,    0,    0,    0,    0,    0, 7462,    0]),\n","  tensor([1154,    0,    0,    0,    0,    0, 2107,    0]),\n","  tensor([3300,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([119,   0,   0,   0,   0,   0, 157,   0]),\n","  tensor([ 3473,     0,     0,     0,     0,     0, 11612,     0]),\n","  tensor([ 117,    0,    0,    0,    0,    0, 1942,    0]),\n","  tensor([ 1128,     0,     0,     0,     0,     0, 19432,     0]),\n","  tensor([1431,    0,    0,    0,    0,    0,  145,    0]),\n","  tensor([ 1221,     0,     0,     0,     0,     0, 17056,     0]),\n","  tensor([1115,    0,    0,    0,    0,    0, 9686,    0]),\n","  tensor([1103,    0,    0,    0,    0,    0,  160,    0]),\n","  tensor([ 109,    0,    0,    0,    0,    0, 9565,    0]),\n","  tensor([ 1275,     0,     0,     0,     0,     0, 25370,     0]),\n","  tensor([4733,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([2426,    0,    0,    0,    0,    0,  165,    0]),\n","  tensor([2502,    0,    0,    0,    0,    0,  107,    0]),\n","  tensor([1107,    0,    0,    0,    0,    0, 1398,    0]),\n","  tensor([1103,    0,    0,    0,    0,    0, 1107,    0]),\n","  tensor([4592,    0,    0,    0,    0,    0,  170,    0]),\n","  tensor([2853,    0,    0,    0,    0,    0, 4632,    0]),\n","  tensor([119,   0,   0,   0,   0,   0, 117,   0]),\n","  tensor([ 1789,     0,     0,     0,     0,     0, 19067,     0]),\n","  tensor([1336,    0,    0,    0,    0,    0, 1490,    0]),\n","  tensor([4752,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([1167,    0,    0,    0,    0,    0,  165,    0]),\n","  tensor([26704,     0,     0,     0,     0,     0,   183,     0]),\n","  tensor([1137,    0,    0,    0,    0,    0,  165,    0]),\n","  tensor([9323,    0,    0,    0,    0,    0,  183,    0]),\n","  tensor([ 117,    0,    0,    0,    0,    0, 2240,    0]),\n","  tensor([1134,    0,    0,    0,    0,    0, 6699,    0]),\n","  tensor([1169,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([1129,    0,    0,    0,    0,    0, 6462,    0]),\n","  tensor([22726,     0,     0,     0,     0,     0,  1108,     0]),\n","  tensor([ 119,    0,    0,    0,    0,    0, 1198,    0]),\n","  tensor([  165,     0,     0,     0,     0,     0, 10899,     0]),\n","  tensor([183,   0,   0,   0,   0,   0, 119,   0]),\n","  tensor([ 165,    0,    0,    0,    0,    0, 6424,    0]),\n","  tensor([ 183,    0,    0,    0,    0,    0, 1609,    0]),\n","  tensor([1708,    0,    0,    0,    0,    0, 1113,    0]),\n","  tensor([1200,    0,    0,    0,    0,    0, 6092,    0]),\n","  tensor([14301,     0,     0,     0,     0,     0,  1105,     0]),\n","  tensor([1110,    0,    0,    0,    0,    0, 2302,    0]),\n","  tensor([1579,    0,    0,    0,    0,    0, 1113,    0]),\n","  tensor([ 3613,     0,     0,     0,     0,     0, 10928,     0]),\n","  tensor([1105,    0,    0,    0,    0,    0, 1610,    0]),\n","  tensor([4931,    0,    0,    0,    0,    0, 4832,    0]),\n","  tensor([119,   0,   0,   0,   0,   0, 117,   0]),\n","  tensor([1220,    0,    0,    0,    0,    0, 1133,    0]),\n","  tensor([1202,    0,    0,    0,    0,    0, 1122,    0]),\n","  tensor([ 170,    0,    0,    0,    0,    0, 1108,    0]),\n","  tensor([7310,    0,    0,    0,    0,    0, 1536,    0]),\n","  tensor([2261,    0,    0,    0,    0,    0, 1106,    0]),\n","  tensor([1104,    0,    0,    0,    0,    0, 1243,    0]),\n","  tensor([1143,    0,    0,    0,    0,    0, 1366,    0]),\n","  tensor([26271,     0,     0,     0,     0,     0,  1149,     0]),\n","  tensor([4404,    0,    0,    0,    0,    0, 1104,    0]),\n","  tensor([3791,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([ 119,    0,    0,    0,    0,    0, 1442,    0]),\n","  tensor([25574,     0,     0,     0,     0,     0,  1107,     0]),\n","  tensor([1193,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([1144,    0,    0,    0,    0,    0, 2106,    0]),\n","  tensor([1122,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([1435,    0,    0,    0,    0,    0, 1284,    0]),\n","  tensor([1106,    0,    0,    0,    0,    0, 3851,    0]),\n","  tensor([2789,    0,    0,    0,    0,    0, 1142,    0]),\n","  tensor([1115,    0,    0,    0,    0,    0, 3415,    0]),\n","  tensor([1139,    0,    0,    0,    0,    0,  117,    0]),\n","  tensor([1546,    0,    0,    0,    0,    0, 1133,    0]),\n","  tensor([1144,    0,    0,    0,    0,    0, 1547,    0]),\n","  tensor([1151,    0,    0,    0,    0,    0, 3644,    0]),\n","  tensor([12477,     0,     0,     0,     0,     0,  1142,     0]),\n","  tensor([1233,    0,    0,    0,    0,    0, 2440,    0]),\n","  tensor([ 118,    0,    0,    0,    0,    0, 2001,    0]),\n","  tensor([4653,    0,    0,    0,    0,    0,  154,    0]),\n","  tensor([  119,     0,     0,     0,     0,     0, 14846,     0]),\n","  tensor([18911,     0,     0,     0,     0,     0,  1777,     0]),\n","  tensor([1113,    0,    0,    0,    0,    0, 1272,    0]),\n","  tensor([1231,    0,    0,    0,    0,    0, 1104,    0]),\n","  tensor([18591,     0,     0,     0,     0,     0,  1115,     0]),\n","  tensor([1116,    0,    0,    0,    0,    0, 5141,    0]),\n","  tensor([1105,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([ 146,    0,    0,    0,    0,    0, 1258,    0]),\n","  tensor([1567,    0,    0,    0,    0,    0, 2005,    0]),\n","  tensor([1115,    0,    0,    0,    0,    0, 1104,    0]),\n","  tensor([1152,    0,    0,    0,    0,    0, 3759,    0]),\n","  tensor([1579,    0,    0,    0,    0,    0,  117,    0]),\n","  tensor([2906,    0,    0,    0,    0,    0, 1195,    0]),\n","  tensor([ 170,    0,    0,    0,    0,    0, 1328,    0]),\n","  tensor([1106,    0,    0,    0,    0,    0, 8402,    0]),\n","  tensor([ 118,    0,    0,    0,    0,    0, 1105,    0]),\n","  tensor([1301,    0,    0,    0,    0,    0, 1136,    0]),\n","  tensor([24802,     0,     0,     0,     0,     0, 14708,     0]),\n","  tensor([  119,     0,     0,     0,     0,     0, 26635,     0]),\n","  tensor([ 165,    0,    0,    0,    0,    0, 1121,    0]),\n","  tensor([107,   0,   0,   0,   0,   0, 170,   0]),\n","  tensor([2009,    0,    0,    0,    0,    0, 2546,    0]),\n","  tensor([ 117,    0,    0,    0,    0,    0, 1420,    0]),\n","  tensor([4208,    0,    0,    0,    0,    0, 1115,    0]),\n","  tensor([ 106,    0,    0,    0,    0,    0, 9521,    0]),\n","  tensor([ 146,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([1156,    0,    0,    0,    0,    0, 6363,    0]),\n","  tensor([1567,    0,    0,    0,    0,    0, 1115,    0]),\n","  tensor([ 170,    0,    0,    0,    0,    0, 2498,    0]),\n","  tensor([10211,     0,     0,     0,     0,     0, 22593,     0]),\n","  tensor([ 1884,     0,     0,     0,     0,     0, 14517,     0]),\n","  tensor([2391,    0,    0,    0,    0,    0, 1154,    0]),\n","  tensor([1106,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([1301,    0,    0,    0,    0,    0, 4045,    0]),\n","  tensor([106,   0,   0,   0,   0,   0, 119,   0]),\n","  tensor([1731,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([17873,     0,     0,     0,     0,     0,   119,     0]),\n","  tensor([106,   0,   0,   0,   0,   0, 119,   0]),\n","  tensor([165,   0,   0,   0,   0,   0, 165,   0]),\n","  tensor([107,   0,   0,   0,   0,   0, 183,   0]),\n","  tensor([12004,     0,     0,     0,     0,     0,   165,     0]),\n","  tensor([1277,    0,    0,    0,    0,    0,  183,    0]),\n","  tensor([1579,    0,    0,    0,    0,    0, 1592,    0]),\n","  tensor([1139,    0,    0,    0,    0,    0, 3447,    0]),\n","  tensor([1354,    0,    0,    0,    0,    0, 1186,    0]),\n","  tensor([1965,    0,    0,    0,    0,    0, 1104,    0]),\n","  tensor([ 119,    0,    0,    0,    0,    0, 3805,    0]),\n","  tensor([165,   0,   0,   0,   0,   0, 131,   0]),\n","  tensor([ 183,    0,    0,    0,    0,    0, 1192,    0]),\n","  tensor([ 165,    0,    0,    0,    0,    0, 1169,    0]),\n","  tensor([ 183,    0,    0,    0,    0,    0, 4837,    0]),\n","  tensor([1942,    0,    0,    0,    0,    0,  170,    0]),\n","  tensor([27516,     0,     0,     0,     0,     0,  1395,     0]),\n","  tensor([1282,    0,    0,    0,    0,    0, 1114,    0]),\n","  tensor([1145,    0,    0,    0,    0,    0,  170,    0]),\n","  tensor([1674,    0,    0,    0,    0,    0, 3621,    0]),\n","  tensor([1554,    0,    0,    0,    0,    0,  117,    0]),\n","  tensor([4014,    0,    0,    0,    0,    0, 1133,    0]),\n","  tensor([6665,    0,    0,    0,    0,    0, 1128,    0]),\n","  tensor([1105,    0,    0,    0,    0,    0, 1538,    0]),\n","  tensor([ 1144,     0,     0,     0,     0,     0, 18589,     0]),\n","  tensor([28117,     0,     0,     0,     0,     0, 23161,     0]),\n","  tensor([5933,    0,    0,    0,    0,    0, 1519,    0]),\n","  tensor([ 119,    0,    0,    0,    0,    0, 1172,    0]),\n","  tensor([8853,    0,    0,    0,    0,    0, 1508,    0]),\n","  tensor([1104,    0,    0,    0,    0,    0,  170,    0]),\n","  tensor([1134,    0,    0,    0,    0,    0, 2080,    0]),\n","  tensor([ 146,    0,    0,    0,    0,    0, 1113,    0]),\n","  tensor([1138,    0,    0,    0,    0,    0, 1240,    0]),\n","  tensor([1793,    0,    0,    0,    0,    0, 3621,    0]),\n","  tensor([1106,    0,    0,    0,    0,    0, 1111,    0]),\n","  tensor([2236,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([ 117,    0,    0,    0,    0,    0, 1554,    0]),\n","  tensor([1133,    0,    0,    0,    0,    0, 1395,    0]),\n","  tensor([1156,    0,    0,    0,    0,    0, 2971,    0]),\n","  tensor([11786,     0,     0,     0,     0,     0,  1235,     0]),\n","  tensor([ 184,    0,    0,    0,    0,    0, 4031,    0]),\n","  tensor([1830,    0,    0,    0,    0,    0, 3554,    0]),\n","  tensor([2646,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([2176,    0,    0,    0,    0,    0, 1192,    0]),\n","  tensor([1191,    0,    0,    0,    0,    0, 1169,    0]),\n","  tensor([1103,    0,    0,    0,    0,    0, 2653,    0]),\n","  tensor([5146,    0,    0,    0,    0,    0, 5948,    0]),\n","  tensor([1108,    0,    0,    0,    0,    0, 1120,    0]),\n","  tensor([2756,    0,    0,    0,    0,    0, 4031,    0]),\n","  tensor([ 119,    0,    0,    0,    0,    0, 3554,    0]),\n","  tensor([165,   0,   0,   0,   0,   0, 119,   0]),\n","  tensor([ 183,    0,    0,    0,    0,    0, 1188,    0]),\n","  tensor([ 165,    0,    0,    0,    0,    0, 1445,    0]),\n","  tensor([183,   0,   0,   0,   0,   0, 112,   0]),\n","  tensor([1942,    0,    0,    0,    0,    0,  189,    0]),\n","  tensor([3822,    0,    0,    0,    0,    0, 3716,    0]),\n","  tensor([4616,    0,    0,    0,    0,    0, 1106,    0]),\n","  tensor([1111,    0,    0,    0,    0,    0, 1366,    0]),\n","  tensor([1103,    0,    0,    0,    0,    0, 1235,    0]),\n","  tensor([3613,    0,    0,    0,    0,    0, 1195,    0]),\n","  tensor([1105,    0,    0,    0,    0,    0, 1127,    0]),\n","  tensor([15021,     0,     0,     0,     0,     0,  1120,     0]),\n","  tensor([5953,    0,    0,    0,    0,    0, 1103,    0]),\n","  tensor([ 120,    0,    0,    0,    0,    0, 4073,    0]),\n","  tensor([1555,    0,    0,    0,    0,    0,  119,    0]),\n","  tensor([117,   0,   0,   0,   0,   0, 102,   0]),\n","  tensor([14812,     0,     0,     0,     0,     0,     0,     0]),\n","  tensor([16442,     0,     0,     0,     0,     0,     0,     0]),\n","  tensor([1186,    0,    0,    0,    0,    0,    0,    0]),\n","  tensor([106,   0,   0,   0,   0,   0,   0,   0]),\n","  tensor([102,   0,   0,   0,   0,   0,   0,   0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0]),\n","  tensor([0, 0, 0, 0, 0, 0, 0, 0])]}"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["model (**blub)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"oNCuf8D4ZzjU","executionInfo":{"status":"error","timestamp":1657126847929,"user_tz":-120,"elapsed":8,"user":{"displayName":"Dr. H. Felix Wittmann","userId":"12199222889078622399"}},"outputId":"4307dc7b-5943-4884-9da7-ed3118f5e038"},"execution_count":60,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-ccce5cc7ed2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mblub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         )\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"iWFKWa4WdCFC"},"execution_count":null,"outputs":[]}]}